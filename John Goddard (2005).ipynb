{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This botebook is to build machine learning classifier for predicting H-D-A or double chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering idea is borrowed from paper:\n",
    "\n",
    ">Regression models for forecasting goals and match results in association football, John Goddard (2005)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2634,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from football.datasets import load_EPL,load_Spain,load_France,load_Germany,load_Italy\n",
    "\n",
    "f1, f2, f3, f4, f5 = load_EPL, load_Spain, load_France, load_Germany, load_Italy\n",
    "# choose a league\n",
    "load_league = f1\n",
    "\n",
    "df1 = pd.concat([load_league('2008-2009').data, load_league('2009-2010').data], ignore_index=True)\n",
    "df2 = pd.concat([load_league('2010-2011').data, load_league('2011-2012').data, load_league('2012-2013').data, load_league('2013-2014').data, load_league('2014-2015').data], \\\n",
    "                      ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FeatureEngineer(df1, df2, which_predictors = range(1, 28), real_predict=False):\n",
    "    '''\n",
    "    Return a dataframe of predictors given the raw dataset.\n",
    "\n",
    "    Predictors:\n",
    "    -------------------------------------------------------------------------\n",
    "    x1:  average number of goals scored by team i, past 0~12 months\n",
    "    x2:  average number of goals scored by team i, past 12~24 months\n",
    "    x3:  average number of goals conceded by team i, past 0~12 months\n",
    "    x4:  average number of goals conceded by team i, past 12~24 months\n",
    "\n",
    "    x5:  average number of goals scored by team j, past 0~12 months\n",
    "    x6:  average number of goals scored by team j, past 12~24 months\n",
    "    x7:  average number of goals conceded by team j, past 0~12 months\n",
    "    x8:  average number of goals conceded by team j, past 12~24 months\n",
    "    -------------------------------------------------------------------------\n",
    "    x9:  average match results team i, past 0~12 months\n",
    "    x10: average match results team i, past 12~24 months\n",
    "    x11: average match results team j, past 0~12 months\n",
    "    x12: average match results team j, past 12~24 months\n",
    "    (win=1, draw=0.5,lose=0)\n",
    "    -------------------------------------------------------------------------\n",
    "    x13: goals scored at home team i, recent 5 matches\n",
    "    x14: goals scored away team i, recent 5 matches\n",
    "    x15: goals conceded at home team i, recent 5 matches\n",
    "    x16: goals conceded away team i, recent 5 matches\n",
    "\n",
    "    x17: goals scored at home team j, recent 5 matches\n",
    "    x18: goals scored away team j, recent 5 matches\n",
    "    x19: goals conceded at home team j, recent 5 matches\n",
    "    x20: goals conceded away team j, recent 5 matches\n",
    "    -------------------------------------------------------------------------\n",
    "    x21: match results at home team i, recent 5 matches\n",
    "    x22: match results away team i, recent 5 matches\n",
    "    x23: match results at home team j, recent 5 matches\n",
    "    x24: match results away team j, recent 5 matches\n",
    "    (win=1, draw=0.5,lose=0)\n",
    "    -------------------------------------------------------------------------\n",
    "\n",
    "    x25: home win odds\n",
    "    x26: draw odds\n",
    "    x27: away win odds\n",
    "\n",
    "    -------------------------------------------------------------------------\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    df1: pd.DataFrame, [season1, season2]\n",
    "    df2: pd.DataFrame, [season3, season4,...]\n",
    "    which_predictors: list, decide which predictors to use, e.g. range(1, 11) + [25,26,27]\n",
    "    real_predict: True, False. for real pre-match betting, match outcomes are unknown before kick-off\n",
    "\n",
    "    '''\n",
    "\n",
    "    N_past = len(df1.Date)\n",
    "    N_train = len(df2.Date)\n",
    "\n",
    "    # FTR is not known for real pre-match betting\n",
    "    if real_predict:\n",
    "        #convert FTR to match points\n",
    "        valH, valA = {'H':1.0, 'D':0.5, 'A':0.0}, {'H':0.0, 'D':0.5, 'A':1.0}\n",
    "        df1['FTRH'] = [valH[res] for res in df1.FTR]\n",
    "        df1['FTRA'] = [valA[res] for res in df1.FTR]\n",
    "        #df2.fillna(0)\n",
    "        dataset = pd.concat([df1,df2], ignore_index=True)[['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'FTRH', 'FTRA']]\n",
    "    # just doing researching on historic dataset, results are all known\n",
    "    else:\n",
    "        dataset = pd.concat([df1,df2], ignore_index=True)[['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']]\n",
    "        #convert FTR to match points\n",
    "        valH, valA = {'H':1.0, 'D':0.5, 'A':0.0}, {'H':0.0, 'D':0.5, 'A':1.0}\n",
    "        dataset['FTRH'] = [valH[res] for res in dataset.FTR]\n",
    "        dataset['FTRA'] = [valA[res] for res in dataset.FTR]\n",
    "\n",
    "    all_predictors = ['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','x11','x12','x13','x14', \\\n",
    "                     'x15','x16','x17','x18','x19','x20','x21','x22','x23','x24', 'x25', 'x26', 'x27']\n",
    "    use_predictors = [u for (i,u) in enumerate(all_predictors) if (i+1) in which_predictors]\n",
    "\n",
    "    predictors = \\\n",
    "    pd.DataFrame([[0.0]*len(use_predictors)]*N_train, dtype=float, \\\n",
    "             columns=use_predictors \\\n",
    "            )\n",
    "\n",
    "    print 'Feature Engineering Task(part by part)\\n\\nPart 1 Loading.'\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    if 'x1' in use_predictors:\n",
    "        #x1:  average number of goals scored by team i, past 0~12 months\n",
    "        f = lambda i: \\\n",
    "        ((dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'FTHG'][dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'HomeTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum() + \\\n",
    "        (dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'FTAG'][dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'AwayTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum()) / 38.0\n",
    "        predictors['x1'] = [f(i) for i in range(N_train)]\n",
    "    if 'x2' in use_predictors:\n",
    "        #x2:  average number of goals scored by team i, past 12~24 months\n",
    "        f = lambda i: \\\n",
    "        ((dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'FTHG'][dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'HomeTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum() + \\\n",
    "        (dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'FTAG'][dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'AwayTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum()) / 38.0\n",
    "        predictors['x2'] = [f(i) for i in range(N_train)]\n",
    "    if 'x3' in use_predictors:\n",
    "        #x3:  average number of goals conceded by team i, past 0~12 months\n",
    "        f = lambda i: \\\n",
    "        ((dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'FTAG'][dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'HomeTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum() + \\\n",
    "        (dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'FTHG'][dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'AwayTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum()) / 38.0\n",
    "        predictors['x3'] = [f(i) for i in range(N_train)]\n",
    "    if 'x4' in use_predictors:\n",
    "        #x4:  average number of goals conceded by team i, past 12~24 months\n",
    "        f = lambda i: \\\n",
    "        ((dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'FTAG'][dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'HomeTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum() + \\\n",
    "        (dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'FTHG'][dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'AwayTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum()) / 38.0\n",
    "        predictors['x4'] = [f(i) for i in range(N_train)]\n",
    "\n",
    "    if 'x5' in use_predictors:\n",
    "        #x5:  average number of goals scored by team j, past 0~12 months\n",
    "        f = lambda i: \\\n",
    "        ((dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'FTHG'][dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'HomeTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum() + \\\n",
    "        (dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'FTAG'][dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'AwayTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum()) / 38.0\n",
    "        predictors['x5'] = [f(i) for i in range(N_train)]\n",
    "    if 'x6' in use_predictors:\n",
    "        #x6:  average number of goals scored by team j, past 12~24 months\n",
    "        f = lambda i: \\\n",
    "        ((dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'FTHG'][dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'HomeTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum() + \\\n",
    "        (dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'FTAG'][dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'AwayTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum()) / 38.0\n",
    "        predictors['x6'] = [f(i) for i in range(N_train)]\n",
    "    if 'x7' in use_predictors:\n",
    "        #x7:  average number of goals conceded by team j, past 0~12 months\n",
    "        f = lambda i: \\\n",
    "        ((dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'FTAG'][dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'HomeTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum() + \\\n",
    "        (dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'FTHG'][dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'AwayTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum()) / 38.0\n",
    "        predictors['x7'] = [f(i) for i in range(N_train)]\n",
    "    if 'x8' in use_predictors:\n",
    "        #x8:  average number of goals conceded by team j, past 12~24 months\n",
    "        f = lambda i: \\\n",
    "        ((dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'FTAG'][dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'HomeTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum() + \\\n",
    "        (dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'FTHG'][dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'AwayTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum()) / 38.0\n",
    "        predictors['x8'] = [f(i) for i in range(N_train)]\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    print 'Part 2 Loading.'\n",
    "\n",
    "    if 'x9' in use_predictors:\n",
    "        #x9:  average match results team i, past 0~12 months\n",
    "        f = lambda i: \\\n",
    "        ((dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'FTRH'][dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'HomeTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum() + \\\n",
    "        (dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'FTRA'][dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'AwayTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum()) / 38.0\n",
    "        predictors['x9'] = [f(i) for i in range(N_train)]\n",
    "    if 'x10' in use_predictors:\n",
    "        #x10: average match results team i, past 12~24 months\n",
    "        f = lambda i: \\\n",
    "        ((dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'FTRH'][dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'HomeTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum() + \\\n",
    "        (dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'FTRA'][dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'AwayTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum()) / 38.0\n",
    "        predictors['x10'] = [f(i) for i in range(N_train)]\n",
    "    if 'x11' in use_predictors:\n",
    "        #x11: average match results team j, past 0~12 months\n",
    "        f = lambda i: \\\n",
    "        ((dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'FTRH'][dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'HomeTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum() + \\\n",
    "        (dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'FTRA'][dataset.loc[(i/10*10+N_past-380):(i/10*10+N_past-1), 'AwayTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum()) / 38.0\n",
    "        predictors['x11'] = [f(i) for i in range(N_train)]\n",
    "    if 'x12' in use_predictors:\n",
    "        #x12: average match results team j, past 12~24 months\n",
    "        f = lambda i: \\\n",
    "        ((dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'FTRH'][dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'HomeTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum() + \\\n",
    "        (dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'FTRA'][dataset.loc[(i/10*10+N_past-760):(i/10*10+N_past-381), 'AwayTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum()) / 38.0\n",
    "        predictors['x12'] = [f(i) for i in range(N_train)]\n",
    "        #(win=1, draw=0.5,lose=0)\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    print 'Part 3 Loading.'\n",
    "\n",
    "    if 'x13' in use_predictors:\n",
    "        #x13: goals scored at home team i, recent 5 matches\n",
    "        f = lambda i: \\\n",
    "        (dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'FTHG'][dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'HomeTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum()\n",
    "        predictors['x13'] = [f(i) for i in range(N_train)]\n",
    "    if 'x14' in use_predictors:\n",
    "        #x14: goals scored away, team i, recent 5 matches\n",
    "        f = lambda i: \\\n",
    "        (dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'FTAG'][dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'AwayTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum()\n",
    "        predictors['x14'] = [f(i) for i in range(N_train)]\n",
    "    if 'x15' in use_predictors:\n",
    "        #x15: goals conceded at home team i, recent 5 matches\n",
    "        f = lambda i: \\\n",
    "        (dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'FTAG'][dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'HomeTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum()\n",
    "        predictors['x15'] = [f(i) for i in range(N_train)]\n",
    "    if 'x16' in use_predictors:\n",
    "        #x16: goals conceded away, team i, recent 5 matches\n",
    "        f = lambda i: \\\n",
    "        (dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'FTHG'][dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'AwayTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum()\n",
    "        predictors['x16'] = [f(i) for i in range(N_train)]\n",
    "\n",
    "    if 'x17' in use_predictors:\n",
    "        #x17: goals scored at home team j, recent 5 matches\n",
    "        f = lambda i: \\\n",
    "        (dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'FTHG'][dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'HomeTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum()\n",
    "        predictors['x17'] = [f(i) for i in range(N_train)]\n",
    "    if 'x18' in use_predictors:\n",
    "        #x18: goals scored away team j, recent 5 matches\n",
    "        f = lambda i: \\\n",
    "        (dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'FTAG'][dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'AwayTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum()\n",
    "        predictors['x18'] = [f(i) for i in range(N_train)]\n",
    "    if 'x19' in use_predictors:\n",
    "        #x19: goals conceded at home team j, recent 5 matches\n",
    "        f = lambda i: \\\n",
    "        (dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'FTAG'][dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'HomeTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum()\n",
    "        predictors['x19'] = [f(i) for i in range(N_train)]\n",
    "    if 'x20' in use_predictors:\n",
    "        #x20: goals conceded away team j, recent 5 matches\n",
    "        f = lambda i: \\\n",
    "        (dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'FTHG'][dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'AwayTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum()\n",
    "        predictors['x20'] = [f(i) for i in range(N_train)]\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    print 'Part 4 Loading.'\n",
    "\n",
    "    if 'x21' in use_predictors:\n",
    "        #x21: match results at home team i, recent 5 matches\n",
    "        f = lambda i: \\\n",
    "        (dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'FTRH'][dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'HomeTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum()\n",
    "        predictors['x21'] = [f(i) for i in range(N_train)]\n",
    "    if 'x22' in use_predictors:\n",
    "        #x22: match results away, team i, recent 5 matches\n",
    "        f = lambda i: \\\n",
    "        (dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'FTRA'][dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'AwayTeam']==dataset.loc[i+N_past, 'HomeTeam']]).sum()\n",
    "        predictors['x22'] = [f(i) for i in range(N_train)]\n",
    "    if 'x23' in use_predictors:\n",
    "        #x23: match results at home team j, recent 5 matches\n",
    "        f = lambda i: \\\n",
    "        (dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'FTRH'][dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'HomeTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum()\n",
    "        predictors['x23'] = [f(i) for i in range(N_train)]\n",
    "    if 'x24' in use_predictors:\n",
    "        #x24: match results away, team j, recent 5 matches\n",
    "        f = lambda i: \\\n",
    "        (dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'FTRA'][dataset.loc[(i/10*10+N_past-5):(i/10*10+N_past-1), 'AwayTeam']==dataset.loc[i+N_past, 'AwayTeam']]).sum()\n",
    "        predictors['x24'] = [f(i) for i in range(N_train)]\n",
    "        #(win=1, draw=0.5,lose=0)\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    print 'Part 5 Loading.'\n",
    "\n",
    "    #x25: win-draw-win odds for each match, on train dataset\n",
    "    if 'x25' in use_predictors:\n",
    "        # assign a col to another, the indexes of these two columns must be identical\n",
    "        predictors['x25'] = df2.reset_index(drop=True)['B365H']\n",
    "    if 'x26' in use_predictors:\n",
    "        predictors['x26'] = df2.reset_index(drop=True)['B365D']\n",
    "    if 'x27' in use_predictors:\n",
    "        predictors['x27'] = df2.reset_index(drop=True)['B365A']\n",
    "\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    print '\\nFinishing.'\n",
    "\n",
    "    return predictors\n",
    "\n",
    "\n",
    "\n",
    "def ResponseEngineer(dataset, which=0):\n",
    "    '''\n",
    "    Return a list of response.\n",
    "\n",
    "    Response:\n",
    "\n",
    "    which=0, default\n",
    "    y = 0, home win\n",
    "    y = 1, draw\n",
    "    y = 2, away win\n",
    "\n",
    "    Other types: see [val0, val1, val2, val3]\n",
    "\n",
    "    --------------------------------------------\n",
    "    Parameters:\n",
    "\n",
    "    dataset: pd.DataFrame, training df2\n",
    "    which: int, 0~3\n",
    "\n",
    "    '''\n",
    "    val0 = {'H':0, 'D':1, 'A':2}\n",
    "    val1 = {'H':0, 'D':1, 'A':1}\n",
    "    val2 = {'D':0, 'H':1, 'A':1}\n",
    "    val3 = {'A':0, 'H':1, 'D':1}\n",
    "\n",
    "    # choose a type from [val0, val1, val2, val3]\n",
    "    val = [val0, val1, val2, val3][which]\n",
    "    return [val[res] for res in dataset.FTR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2930,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Task(part by part)\n",
      "\n",
      "Part 1 Loading.\n",
      "Part 2 Loading.\n",
      "Part 3 Loading.\n",
      "Part 4 Loading.\n",
      "Part 5 Loading.\n",
      "\n",
      "Finishing.\n"
     ]
    }
   ],
   "source": [
    "# e.g. x1, x2,..., x24\n",
    "X = FeatureEngineer(df1, df2, which_predictors=range(1,25), real_predict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2931,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = ResponseEngineer(df2, which=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2636,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1.368421</td>\n",
       "      <td> 1.421053</td>\n",
       "      <td> 1.026316</td>\n",
       "      <td> 1.263158</td>\n",
       "      <td> 1.236842</td>\n",
       "      <td> 1.105263</td>\n",
       "      <td> 1.736842</td>\n",
       "      <td> 1.184211</td>\n",
       "      <td> 0.618421</td>\n",
       "      <td> 0.592105</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.5</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1.078947</td>\n",
       "      <td> 1.052632</td>\n",
       "      <td> 1.447368</td>\n",
       "      <td> 1.578947</td>\n",
       "      <td> 1.578947</td>\n",
       "      <td> 1.447368</td>\n",
       "      <td> 1.289474</td>\n",
       "      <td> 0.973684</td>\n",
       "      <td> 0.486842</td>\n",
       "      <td> 0.407895</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1.105263</td>\n",
       "      <td> 1.078947</td>\n",
       "      <td> 1.763158</td>\n",
       "      <td> 1.394737</td>\n",
       "      <td> 1.026316</td>\n",
       "      <td> 1.026316</td>\n",
       "      <td> 1.210526</td>\n",
       "      <td> 0.894737</td>\n",
       "      <td> 0.381579</td>\n",
       "      <td> 0.394737</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 2.710526</td>\n",
       "      <td> 1.789474</td>\n",
       "      <td> 0.842105</td>\n",
       "      <td> 0.631579</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.947368</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.763158</td>\n",
       "      <td> 0.776316</td>\n",
       "      <td> 0.763158</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 1.263158</td>\n",
       "      <td> 0.894737</td>\n",
       "      <td> 1.473684</td>\n",
       "      <td> 1.421053</td>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.236842</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.434211</td>\n",
       "      <td> 0.355263</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0  1.368421  1.421053  1.026316  1.263158  1.236842  1.105263  1.736842   \n",
       "1  1.078947  1.052632  1.447368  1.578947  1.578947  1.447368  1.289474   \n",
       "2  1.105263  1.078947  1.763158  1.394737  1.026316  1.026316  1.210526   \n",
       "3  2.710526  1.789474  0.842105  0.631579  0.000000  0.947368  0.000000   \n",
       "4  1.263158  0.894737  1.473684  1.421053  1.000000  0.000000  1.236842   \n",
       "\n",
       "         x8        x9       x10 ...   x15  x16  x17  x18  x19  x20  x21  x22  \\\n",
       "0  1.184211  0.618421  0.592105 ...     0    0    1    0    1    0    0    0   \n",
       "1  0.973684  0.486842  0.407895 ...     0    0    1    0    0    0    0    0   \n",
       "2  0.894737  0.381579  0.394737 ...     0    0    0    0    0    0    0    0   \n",
       "3  1.763158  0.776316  0.763158 ...     0    0    0    0    0    0    0    0   \n",
       "4  0.000000  0.434211  0.355263 ...     0    2    0    0    0    0    0    0   \n",
       "\n",
       "   x23  x24  \n",
       "0  0.5    0  \n",
       "1  1.0    0  \n",
       "2  0.0    0  \n",
       "3  0.0    0  \n",
       "4  0.0    0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[0:4, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2932,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1]"
      ]
     },
     "execution_count": 2932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### first classifier: a simple SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "{'kernel': 'linear', 'C': 0.3}\n",
      "\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.0001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.01}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.10000000000000001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 1.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 10.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 100.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 1000.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 0.0001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 0.001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 0.01}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 0.10000000000000001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 1.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 10.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 100.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 1000.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.0001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.01}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.10000000000000001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 1.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 10.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 100.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 1000.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 0.0001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 0.001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 0.01}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 0.10000000000000001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 1.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 10.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 100.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 1000.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.0001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.01}\n",
      "0.477 (+/-0.028) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.10000000000000001}\n",
      "0.457 (+/-0.016) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 1.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 10.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 100.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 1000.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 0.0001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 0.001}\n",
      "0.457 (+/-0.010) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 0.01}\n",
      "0.519 (+/-0.042) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 0.10000000000000001}\n",
      "0.481 (+/-0.023) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 1.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 10.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 100.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 1000.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.0001}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.001}\n",
      "0.522 (+/-0.036) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.01}\n",
      "0.510 (+/-0.054) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.10000000000000001}\n",
      "0.489 (+/-0.048) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}\n",
      "0.464 (+/-0.013) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 10.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 100.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 1000.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 0.0001}\n",
      "0.463 (+/-0.010) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 0.001}\n",
      "0.535 (+/-0.043) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 0.01}\n",
      "0.496 (+/-0.090) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 0.10000000000000001}\n",
      "0.462 (+/-0.092) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 1.0}\n",
      "0.458 (+/-0.027) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 10.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 100.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 1000.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'linear', 'C': 0.001}\n",
      "0.457 (+/-0.003) for {'kernel': 'linear', 'C': 0.003}\n",
      "0.518 (+/-0.027) for {'kernel': 'linear', 'C': 0.01}\n",
      "0.532 (+/-0.028) for {'kernel': 'linear', 'C': 0.03}\n",
      "0.534 (+/-0.040) for {'kernel': 'linear', 'C': 0.1}\n",
      "0.537 (+/-0.036) for {'kernel': 'linear', 'C': 0.3}\n",
      "0.529 (+/-0.053) for {'kernel': 'linear', 'C': 1.0}\n",
      "0.530 (+/-0.054) for {'kernel': 'linear', 'C': 3.0}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.001, 'degree': 1}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.001, 'degree': 2}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.001, 'degree': 3}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.001, 'degree': 4}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.001, 'degree': 5}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.001, 'degree': 6}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.001, 'degree': 7}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.001, 'degree': 8}\n",
      "0.457 (+/-0.007) for {'kernel': 'poly', 'C': 0.001, 'degree': 9}\n",
      "0.458 (+/-0.011) for {'kernel': 'poly', 'C': 0.001, 'degree': 10}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.003, 'degree': 1}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.003, 'degree': 2}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.003, 'degree': 3}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.003, 'degree': 4}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.003, 'degree': 5}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.003, 'degree': 6}\n",
      "0.456 (+/-0.006) for {'kernel': 'poly', 'C': 0.003, 'degree': 7}\n",
      "0.457 (+/-0.007) for {'kernel': 'poly', 'C': 0.003, 'degree': 8}\n",
      "0.456 (+/-0.006) for {'kernel': 'poly', 'C': 0.003, 'degree': 9}\n",
      "0.456 (+/-0.013) for {'kernel': 'poly', 'C': 0.003, 'degree': 10}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.01, 'degree': 1}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.01, 'degree': 2}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.01, 'degree': 3}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.01, 'degree': 4}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.01, 'degree': 5}\n",
      "0.457 (+/-0.007) for {'kernel': 'poly', 'C': 0.01, 'degree': 6}\n",
      "0.458 (+/-0.011) for {'kernel': 'poly', 'C': 0.01, 'degree': 7}\n",
      "0.454 (+/-0.017) for {'kernel': 'poly', 'C': 0.01, 'degree': 8}\n",
      "0.453 (+/-0.022) for {'kernel': 'poly', 'C': 0.01, 'degree': 9}\n",
      "0.454 (+/-0.027) for {'kernel': 'poly', 'C': 0.01, 'degree': 10}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.03, 'degree': 1}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.03, 'degree': 2}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.03, 'degree': 3}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.03, 'degree': 4}\n",
      "0.457 (+/-0.007) for {'kernel': 'poly', 'C': 0.03, 'degree': 5}\n",
      "0.455 (+/-0.010) for {'kernel': 'poly', 'C': 0.03, 'degree': 6}\n",
      "0.455 (+/-0.025) for {'kernel': 'poly', 'C': 0.03, 'degree': 7}\n",
      "0.455 (+/-0.028) for {'kernel': 'poly', 'C': 0.03, 'degree': 8}\n",
      "0.454 (+/-0.031) for {'kernel': 'poly', 'C': 0.03, 'degree': 9}\n",
      "0.456 (+/-0.039) for {'kernel': 'poly', 'C': 0.03, 'degree': 10}\n",
      "0.457 (+/-0.003) for {'kernel': 'poly', 'C': 0.1, 'degree': 1}\n",
      "0.461 (+/-0.009) for {'kernel': 'poly', 'C': 0.1, 'degree': 2}\n",
      "0.461 (+/-0.021) for {'kernel': 'poly', 'C': 0.1, 'degree': 3}\n",
      "0.458 (+/-0.028) for {'kernel': 'poly', 'C': 0.1, 'degree': 4}\n",
      "0.455 (+/-0.021) for {'kernel': 'poly', 'C': 0.1, 'degree': 5}\n",
      "0.453 (+/-0.020) for {'kernel': 'poly', 'C': 0.1, 'degree': 6}\n",
      "0.453 (+/-0.031) for {'kernel': 'poly', 'C': 0.1, 'degree': 7}\n",
      "0.453 (+/-0.036) for {'kernel': 'poly', 'C': 0.1, 'degree': 8}\n",
      "0.454 (+/-0.042) for {'kernel': 'poly', 'C': 0.1, 'degree': 9}\n",
      "0.456 (+/-0.045) for {'kernel': 'poly', 'C': 0.1, 'degree': 10}\n",
      "0.524 (+/-0.036) for {'kernel': 'poly', 'C': 0.3, 'degree': 1}\n",
      "0.525 (+/-0.037) for {'kernel': 'poly', 'C': 0.3, 'degree': 2}\n",
      "0.505 (+/-0.035) for {'kernel': 'poly', 'C': 0.3, 'degree': 3}\n",
      "0.485 (+/-0.036) for {'kernel': 'poly', 'C': 0.3, 'degree': 4}\n",
      "0.484 (+/-0.046) for {'kernel': 'poly', 'C': 0.3, 'degree': 5}\n",
      "0.476 (+/-0.044) for {'kernel': 'poly', 'C': 0.3, 'degree': 6}\n",
      "0.466 (+/-0.051) for {'kernel': 'poly', 'C': 0.3, 'degree': 7}\n",
      "0.462 (+/-0.042) for {'kernel': 'poly', 'C': 0.3, 'degree': 8}\n",
      "0.455 (+/-0.052) for {'kernel': 'poly', 'C': 0.3, 'degree': 9}\n",
      "0.450 (+/-0.046) for {'kernel': 'poly', 'C': 0.3, 'degree': 10}\n",
      "0.533 (+/-0.033) for {'kernel': 'poly', 'C': 1.0, 'degree': 1}\n",
      "0.522 (+/-0.043) for {'kernel': 'poly', 'C': 1.0, 'degree': 2}\n",
      "0.523 (+/-0.047) for {'kernel': 'poly', 'C': 1.0, 'degree': 3}\n",
      "0.515 (+/-0.046) for {'kernel': 'poly', 'C': 1.0, 'degree': 4}\n",
      "0.500 (+/-0.036) for {'kernel': 'poly', 'C': 1.0, 'degree': 5}\n",
      "0.492 (+/-0.040) for {'kernel': 'poly', 'C': 1.0, 'degree': 6}\n",
      "0.481 (+/-0.030) for {'kernel': 'poly', 'C': 1.0, 'degree': 7}\n",
      "0.471 (+/-0.042) for {'kernel': 'poly', 'C': 1.0, 'degree': 8}\n",
      "0.469 (+/-0.063) for {'kernel': 'poly', 'C': 1.0, 'degree': 9}\n",
      "0.466 (+/-0.058) for {'kernel': 'poly', 'C': 1.0, 'degree': 10}\n",
      "0.532 (+/-0.038) for {'kernel': 'poly', 'C': 3.0, 'degree': 1}\n",
      "0.530 (+/-0.044) for {'kernel': 'poly', 'C': 3.0, 'degree': 2}\n",
      "0.535 (+/-0.044) for {'kernel': 'poly', 'C': 3.0, 'degree': 3}\n",
      "0.515 (+/-0.050) for {'kernel': 'poly', 'C': 3.0, 'degree': 4}\n",
      "0.500 (+/-0.042) for {'kernel': 'poly', 'C': 3.0, 'degree': 5}\n",
      "0.487 (+/-0.042) for {'kernel': 'poly', 'C': 3.0, 'degree': 6}\n",
      "0.478 (+/-0.030) for {'kernel': 'poly', 'C': 3.0, 'degree': 7}\n",
      "0.478 (+/-0.048) for {'kernel': 'poly', 'C': 3.0, 'degree': 8}\n",
      "0.470 (+/-0.049) for {'kernel': 'poly', 'C': 3.0, 'degree': 9}\n",
      "0.469 (+/-0.062) for {'kernel': 'poly', 'C': 3.0, 'degree': 10}\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "\n",
      "validation dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.84      0.64       100\n",
      "          1       0.00      0.00      0.00        55\n",
      "          2       0.58      0.52      0.55        73\n",
      "\n",
      "avg / total       0.41      0.54      0.46       228\n",
      "\n",
      "[[84  0 16]\n",
      " [43  0 12]\n",
      " [35  0 38]]\n",
      "\n",
      "\n",
      "train dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.86      0.67       417\n",
      "          1       0.00      0.00      0.00       224\n",
      "          2       0.54      0.52      0.53       271\n",
      "\n",
      "avg / total       0.41      0.55      0.46       912\n",
      "\n",
      "[[359   0  58]\n",
      " [164   0  60]\n",
      " [131   0 140]]\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "{'kernel': 'poly', 'C': 3.0, 'degree': 3}\n",
      "\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.0001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.01}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.10000000000000001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 1.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 10.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 100.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.001, 'gamma': 1000.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 0.0001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 0.001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 0.01}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 0.10000000000000001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 1.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 10.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 100.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.003, 'gamma': 1000.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.0001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.01}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.10000000000000001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 1.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 10.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 100.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.01, 'gamma': 1000.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 0.0001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 0.001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 0.01}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 0.10000000000000001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 1.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 10.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 100.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.03, 'gamma': 1000.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.0001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.01}\n",
      "0.378 (+/-0.091) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.10000000000000001}\n",
      "0.269 (+/-0.240) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 1.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 10.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 100.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 1000.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 0.0001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 0.001}\n",
      "0.259 (+/-0.128) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 0.01}\n",
      "0.389 (+/-0.042) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 0.10000000000000001}\n",
      "0.388 (+/-0.076) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 1.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 10.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 100.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 1000.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.0001}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.001}\n",
      "0.393 (+/-0.037) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.01}\n",
      "0.435 (+/-0.184) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.10000000000000001}\n",
      "0.438 (+/-0.040) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}\n",
      "0.459 (+/-0.168) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 10.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 100.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 1000.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 0.0001}\n",
      "0.376 (+/-0.138) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 0.001}\n",
      "0.402 (+/-0.037) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 0.01}\n",
      "0.436 (+/-0.081) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 0.10000000000000001}\n",
      "0.436 (+/-0.117) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 1.0}\n",
      "0.457 (+/-0.166) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 10.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 100.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'rbf', 'C': 3.0, 'gamma': 1000.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'linear', 'C': 0.001}\n",
      "0.209 (+/-0.002) for {'kernel': 'linear', 'C': 0.003}\n",
      "0.398 (+/-0.052) for {'kernel': 'linear', 'C': 0.01}\n",
      "0.400 (+/-0.025) for {'kernel': 'linear', 'C': 0.03}\n",
      "0.402 (+/-0.036) for {'kernel': 'linear', 'C': 0.1}\n",
      "0.403 (+/-0.032) for {'kernel': 'linear', 'C': 0.3}\n",
      "0.397 (+/-0.042) for {'kernel': 'linear', 'C': 1.0}\n",
      "0.442 (+/-0.132) for {'kernel': 'linear', 'C': 3.0}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.001, 'degree': 1}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.001, 'degree': 2}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.001, 'degree': 3}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.001, 'degree': 4}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.001, 'degree': 5}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.001, 'degree': 6}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.001, 'degree': 7}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.001, 'degree': 8}\n",
      "0.259 (+/-0.198) for {'kernel': 'poly', 'C': 0.001, 'degree': 9}\n",
      "0.294 (+/-0.338) for {'kernel': 'poly', 'C': 0.001, 'degree': 10}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.003, 'degree': 1}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.003, 'degree': 2}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.003, 'degree': 3}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.003, 'degree': 4}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.003, 'degree': 5}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.003, 'degree': 6}\n",
      "0.209 (+/-0.003) for {'kernel': 'poly', 'C': 0.003, 'degree': 7}\n",
      "0.234 (+/-0.100) for {'kernel': 'poly', 'C': 0.003, 'degree': 8}\n",
      "0.255 (+/-0.184) for {'kernel': 'poly', 'C': 0.003, 'degree': 9}\n",
      "0.305 (+/-0.236) for {'kernel': 'poly', 'C': 0.003, 'degree': 10}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.01, 'degree': 1}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.01, 'degree': 2}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.01, 'degree': 3}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.01, 'degree': 4}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.01, 'degree': 5}\n",
      "0.259 (+/-0.198) for {'kernel': 'poly', 'C': 0.01, 'degree': 6}\n",
      "0.294 (+/-0.338) for {'kernel': 'poly', 'C': 0.01, 'degree': 7}\n",
      "0.274 (+/-0.194) for {'kernel': 'poly', 'C': 0.01, 'degree': 8}\n",
      "0.330 (+/-0.259) for {'kernel': 'poly', 'C': 0.01, 'degree': 9}\n",
      "0.282 (+/-0.249) for {'kernel': 'poly', 'C': 0.01, 'degree': 10}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.03, 'degree': 1}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.03, 'degree': 2}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.03, 'degree': 3}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.03, 'degree': 4}\n",
      "0.259 (+/-0.197) for {'kernel': 'poly', 'C': 0.03, 'degree': 5}\n",
      "0.255 (+/-0.184) for {'kernel': 'poly', 'C': 0.03, 'degree': 6}\n",
      "0.360 (+/-0.334) for {'kernel': 'poly', 'C': 0.03, 'degree': 7}\n",
      "0.360 (+/-0.335) for {'kernel': 'poly', 'C': 0.03, 'degree': 8}\n",
      "0.376 (+/-0.311) for {'kernel': 'poly', 'C': 0.03, 'degree': 9}\n",
      "0.407 (+/-0.391) for {'kernel': 'poly', 'C': 0.03, 'degree': 10}\n",
      "0.209 (+/-0.002) for {'kernel': 'poly', 'C': 0.1, 'degree': 1}\n",
      "0.368 (+/-0.240) for {'kernel': 'poly', 'C': 0.1, 'degree': 2}\n",
      "0.386 (+/-0.210) for {'kernel': 'poly', 'C': 0.1, 'degree': 3}\n",
      "0.421 (+/-0.328) for {'kernel': 'poly', 'C': 0.1, 'degree': 4}\n",
      "0.378 (+/-0.196) for {'kernel': 'poly', 'C': 0.1, 'degree': 5}\n",
      "0.414 (+/-0.213) for {'kernel': 'poly', 'C': 0.1, 'degree': 6}\n",
      "0.378 (+/-0.172) for {'kernel': 'poly', 'C': 0.1, 'degree': 7}\n",
      "0.413 (+/-0.205) for {'kernel': 'poly', 'C': 0.1, 'degree': 8}\n",
      "0.419 (+/-0.209) for {'kernel': 'poly', 'C': 0.1, 'degree': 9}\n",
      "0.422 (+/-0.242) for {'kernel': 'poly', 'C': 0.1, 'degree': 10}\n",
      "0.399 (+/-0.047) for {'kernel': 'poly', 'C': 0.3, 'degree': 1}\n",
      "0.402 (+/-0.052) for {'kernel': 'poly', 'C': 0.3, 'degree': 2}\n",
      "0.441 (+/-0.203) for {'kernel': 'poly', 'C': 0.3, 'degree': 3}\n",
      "0.384 (+/-0.080) for {'kernel': 'poly', 'C': 0.3, 'degree': 4}\n",
      "0.460 (+/-0.164) for {'kernel': 'poly', 'C': 0.3, 'degree': 5}\n",
      "0.449 (+/-0.177) for {'kernel': 'poly', 'C': 0.3, 'degree': 6}\n",
      "0.437 (+/-0.180) for {'kernel': 'poly', 'C': 0.3, 'degree': 7}\n",
      "0.412 (+/-0.132) for {'kernel': 'poly', 'C': 0.3, 'degree': 8}\n",
      "0.396 (+/-0.172) for {'kernel': 'poly', 'C': 0.3, 'degree': 9}\n",
      "0.364 (+/-0.161) for {'kernel': 'poly', 'C': 0.3, 'degree': 10}\n",
      "0.401 (+/-0.031) for {'kernel': 'poly', 'C': 1.0, 'degree': 1}\n",
      "0.444 (+/-0.214) for {'kernel': 'poly', 'C': 1.0, 'degree': 2}\n",
      "0.483 (+/-0.189) for {'kernel': 'poly', 'C': 1.0, 'degree': 3}\n",
      "0.479 (+/-0.185) for {'kernel': 'poly', 'C': 1.0, 'degree': 4}\n",
      "0.457 (+/-0.186) for {'kernel': 'poly', 'C': 1.0, 'degree': 5}\n",
      "0.442 (+/-0.153) for {'kernel': 'poly', 'C': 1.0, 'degree': 6}\n",
      "0.418 (+/-0.144) for {'kernel': 'poly', 'C': 1.0, 'degree': 7}\n",
      "0.411 (+/-0.130) for {'kernel': 'poly', 'C': 1.0, 'degree': 8}\n",
      "0.410 (+/-0.155) for {'kernel': 'poly', 'C': 1.0, 'degree': 9}\n",
      "0.402 (+/-0.172) for {'kernel': 'poly', 'C': 1.0, 'degree': 10}\n",
      "0.399 (+/-0.033) for {'kernel': 'poly', 'C': 3.0, 'degree': 1}\n",
      "0.478 (+/-0.170) for {'kernel': 'poly', 'C': 3.0, 'degree': 2}\n",
      "0.492 (+/-0.163) for {'kernel': 'poly', 'C': 3.0, 'degree': 3}\n",
      "0.456 (+/-0.123) for {'kernel': 'poly', 'C': 3.0, 'degree': 4}\n",
      "0.431 (+/-0.068) for {'kernel': 'poly', 'C': 3.0, 'degree': 5}\n",
      "0.409 (+/-0.063) for {'kernel': 'poly', 'C': 3.0, 'degree': 6}\n",
      "0.417 (+/-0.051) for {'kernel': 'poly', 'C': 3.0, 'degree': 7}\n",
      "0.426 (+/-0.101) for {'kernel': 'poly', 'C': 3.0, 'degree': 8}\n",
      "0.420 (+/-0.110) for {'kernel': 'poly', 'C': 3.0, 'degree': 9}\n",
      "0.436 (+/-0.139) for {'kernel': 'poly', 'C': 3.0, 'degree': 10}\n",
      "\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "\n",
      "validation dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.84      0.64       100\n",
      "          1       0.00      0.00      0.00        55\n",
      "          2       0.58      0.47      0.52        73\n",
      "\n",
      "avg / total       0.41      0.52      0.45       228\n",
      "\n",
      "[[84  3 13]\n",
      " [43  0 12]\n",
      " [35  4 34]]\n",
      "\n",
      "\n",
      "train dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.91      0.71       417\n",
      "          1       0.78      0.09      0.17       224\n",
      "          2       0.61      0.51      0.56       271\n",
      "\n",
      "avg / total       0.64      0.59      0.53       912\n",
      "\n",
      "[[379   0  38]\n",
      " [152  21  51]\n",
      " [126   6 139]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = \\\n",
    "[{'kernel': ['rbf'], 'gamma': np.logspace(-4, 3, 8), 'C': [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0]}, \\\n",
    "{'kernel': ['linear'], 'C': [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0]}, \\\n",
    "{'kernel':['poly'], 'degree':[1,2,3,4,5,6,7,8,9,10], 'C': [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0]}]\n",
    "\n",
    "scores = ['recall', 'precision']\n",
    "\n",
    "for score in scores:\n",
    "    print \"# Tuning hyper-parameters for %s\" % score + '\\n'\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print \"Best parameters set found on development set:\"\n",
    "    print clf.best_params_\n",
    "    print '\\n'\n",
    "    print \"Grid scores on development set:\"\n",
    "    print '\\n'\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() * 2, params))\n",
    "    print '\\n'\n",
    "\n",
    "    print \"Detailed classification report:\"\n",
    "    print '\\n'\n",
    "    print \"The model is trained on the full development set.\"\n",
    "    print \"The scores are computed on the full evaluation set.\"\n",
    "    print '\\n'\n",
    "    # prediction on validation dataset\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print 'validation dataset'\n",
    "    print classification_report(y_true, y_pred)\n",
    "    print confusion_matrix(y_true, y_pred)\n",
    "    print '\\n'\n",
    "    # fit on train dataset\n",
    "    y_true, y_pred = y_train, clf.predict(X_train)\n",
    "    print 'train dataset'\n",
    "    print classification_report(y_true, y_pred)\n",
    "    print confusion_matrix(y_true, y_pred)\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 3.0, 'gamma': 1.0} 0.762687001819\n",
      "validation dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.24      0.10      0.14        42\n",
      "          1       0.82      0.93      0.87       186\n",
      "\n",
      "avg / total       0.71      0.78      0.74       228\n",
      "\n",
      "[[  4  38]\n",
      " [ 13 173]]\n",
      "\n",
      "\n",
      "train dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.84      0.90       219\n",
      "          1       0.95      0.99      0.97       693\n",
      "\n",
      "avg / total       0.96      0.96      0.96       912\n",
      "\n",
      "[[184  35]\n",
      " [  4 689]]\n",
      "\n",
      "\n",
      "\n",
      "Precision and Recall:\n",
      "\n",
      "When a search engine returns 30 pages only 20 of which were relevant while failing \n",
      "to return 40 additional relevant pages, its precision is 20/30 = 2/3 while its recall is 20/60 = 1/3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "# parameters = {'C':[0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0]}\n",
    "# clf = LinearSVC(penalty='l2', loss='l2', dual=True, tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None)\n",
    "parameters = {'kernel': ['rbf'], 'gamma': np.logspace(-4, 3, 8), 'C': [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0]}\n",
    "clf = SVC()\n",
    "\n",
    "# try to improve recall\n",
    "gs = GridSearchCV(clf, param_grid=parameters, cv=10, scoring='precision')\n",
    "gs.fit(X_train, y_train)\n",
    "#print gs.grid_scores_\n",
    "print gs.best_params_, gs.best_score_\n",
    "\n",
    "# prediction on validation dataset\n",
    "y_true, y_pred = y_test, gs.predict(X_test)\n",
    "print 'validation dataset'\n",
    "print classification_report(y_true, y_pred)\n",
    "print confusion_matrix(y_true, y_pred)\n",
    "print '\\n'\n",
    "# fit on train dataset\n",
    "y_true, y_pred = y_train, gs.predict(X_train)\n",
    "print 'train dataset'\n",
    "print classification_report(y_true, y_pred)\n",
    "print confusion_matrix(y_true, y_pred)\n",
    "print '\\n'\n",
    "\n",
    "print \\\n",
    "'''\n",
    "Precision and Recall:\n",
    "\n",
    "When a search engine returns 30 pages only 20 of which were relevant while failing \n",
    "to return 40 additional relevant pages, its precision is 20/30 = 2/3 while its recall is 20/60 = 1/3.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### unbalanced labels problem, home win 50%, draw 20%, away win 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "#from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "N_all_samples = len(y)\n",
    "N_draw_samples = (np.array(y)==0).sum()\n",
    "N_HA_samples = N_all_samples - N_draw_samples\n",
    "y_draw = [0]*N_draw_samples\n",
    "y_HA = [1]*N_draw_samples\n",
    "\n",
    "X_draw = X[np.array(y)==0]\n",
    "_X_HA = X[np.array(y)==1]\n",
    "X_draw.reset_index(drop=True, inplace=True)\n",
    "_X_HA.reset_index(drop=True, inplace=True)\n",
    "# draw matches are fewer, randomly subset the HA matches to be same length as draw.\n",
    "index = random.sample( set(range(N_HA_samples)), N_draw_samples )\n",
    "X_HA = _X_HA.ix[index,:]\n",
    "X_HA.reset_index(drop=True, inplace=True)\n",
    "\n",
    "_X = pd.concat([X_draw, X_HA], ignore_index=True)\n",
    "_y = y_draw + y_HA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### try ensemble methods\n",
    ">improving the precision of recognizing Draw games to 40%+, since odds for draw normally 3.0+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2435,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.62      0.56        94\n",
      "          1       0.56      0.45      0.50       100\n",
      "\n",
      "avg / total       0.54      0.53      0.53       194\n",
      "\n",
      "[[58 36]\n",
      " [55 45]]\n",
      "\n",
      "\n",
      "train dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98       389\n",
      "          1       0.99      0.97      0.98       383\n",
      "\n",
      "avg / total       0.98      0.98      0.98       772\n",
      "\n",
      "[[385   4]\n",
      " [ 13 370]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# which =  0.HDA, 1.H DA, 2.D HA, 3.A HD\n",
    "# y = ResponseEngineer(df2, which=2)\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(_X, _y, train_size=0.8)\n",
    "\n",
    "# unbalanced sample. 0 draw : 1 HA = 0.3 : 0.7\n",
    "#sample_weight = np.array([2 if i == 0 else 1 for i in y_train])\n",
    "\n",
    "\n",
    "#gs = SVC(C=1.0, gamma=0.3, kernel='rbf', class_weight={0:1.8, 1:0.9})\n",
    "#gs = BaggingClassifier(base_estimator=SVC(C=1.0, gamma=0.3, kernel='rbf', class_weight={0:1.6, 1:1.0}), n_estimators=50)\n",
    "#gs = BaggingClassifier(base_estimator=SVC(C=1.0, gamma=0.3, kernel='poly', degree=3, class_weight={0:1.6, 1:1.0}), n_estimators=50)\n",
    "#gs = AdaBoostClassifier(base_estimator=SVC(C=1.0, gamma=1.0, kernel='rbf', class_weight={0:1.6, 1:1.0}), n_estimators=50, algorithm='SAMME')\n",
    "#gs = AdaBoostClassifier(base_estimator=RandomForestClassifier(n_estimators=5), n_estimators=50)\n",
    "#gs = GradientBoostingClassifier(n_estimators=500, learning_rate=0.5)\n",
    "#gs = AdaBoostClassifier(base_estimator=SGDClassifier(class_weight={0:1.6, 1:1.0}), n_estimators=500, algorithm='SAMME')\n",
    "#gs = BaggingClassifier(LogisticRegression(C=1.0), n_estimators=50)\n",
    "gs = RandomForestClassifier(n_estimators=10)\n",
    "gs.fit(X_train, y_train)\n",
    "#gs.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "\n",
    "# prediction on validation dataset\n",
    "y_true, y_pred = y_test, gs.predict(X_test)\n",
    "print 'validation dataset'\n",
    "print classification_report(y_true, y_pred)\n",
    "print confusion_matrix(y_true, y_pred)\n",
    "print '\\n'\n",
    "# fit on train dataset\n",
    "y_true, y_pred = y_train, gs.predict(X_train)\n",
    "print 'train dataset'\n",
    "print classification_report(y_true, y_pred)\n",
    "print confusion_matrix(y_true, y_pred)\n",
    "print '\\n'\n",
    "\n",
    "#print 'predict: ', gs.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-sample test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10 new matches, real_predict=True\n",
    "test_df1 = pd.concat([load_league('2013-2014').data, load_league('2014-2015').data, load_league('2015-2016').data[0:109]], ignore_index=True)\n",
    "test_df2 = load_league('2015-2016').data[110:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new full season, real_predict=False\n",
    "test_df1 = pd.concat([load_league('2013-2014').data, load_league('2014-2015').data], ignore_index=True)\n",
    "test_df2 = load_league('2015-2016').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Task(part by part)\n",
      "\n",
      "Part 1 Loading.\n",
      "Part 2 Loading.\n",
      "Part 3 Loading.\n",
      "Part 4 Loading.\n",
      "Part 5 Loading.\n",
      "\n",
      "Finishing.\n"
     ]
    }
   ],
   "source": [
    "# notice the selection of predictors\n",
    "test_X = FeatureEngineer(test_df1, test_df2, which_predictors=range(1, 25), real_predict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# which=2: find Draw games\n",
    "\n",
    "real_predict = False\n",
    "\n",
    "if real_predict:\n",
    "    # real_predict\n",
    "    print 'real predict: ', gs.predict(test_X)\n",
    "else:\n",
    "    # test\n",
    "    test_y = ResponseEngineer(test_df2, which=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27272727272727271"
      ]
     },
     "execution_count": 3231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(test_y)==0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Out-of-sample) Classification accuracy:  0.509090909091\n",
      "----------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.70      0.44        30\n",
      "          1       0.80      0.44      0.56        80\n",
      "\n",
      "avg / total       0.67      0.51      0.53       110\n",
      "\n",
      "----------------------------------------------------------\n",
      "[[21  9]\n",
      " [45 35]]\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 10 matches each round\n",
    "r = 0\n",
    "\n",
    "if r == 0:# all matches\n",
    "    group_test_X = test_X\n",
    "    group_test_y = test_y\n",
    "else:# 10 matches\n",
    "    group_test_X = test_X.ix[range(10*(r-1), 10*r), ]\n",
    "    group_test_y = test_y[10*(r-1):(10*r)]\n",
    "\n",
    "clf_accuracy = (gs.predict(group_test_X) == group_test_y).mean()\n",
    "print '(Out-of-sample) Classification accuracy: ', clf_accuracy\n",
    "print '----------------------------------------------------------'\n",
    "print classification_report(group_test_y, gs.predict(group_test_X))\n",
    "print '----------------------------------------------------------'\n",
    "print confusion_matrix(group_test_y, gs.predict(group_test_X))\n",
    "print '----------------------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.2\n",
      "-2.2\n"
     ]
    }
   ],
   "source": [
    "# put 1 stake on each match equally\n",
    "n_D, n_HA = 21,35\n",
    "stake = 110\n",
    "print n_D*4.2+n_HA*1.2-stake\n",
    "print n_D*2.3+n_HA*1.7-stake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ignore from below this line...\n",
    "### --------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans = {0:'H', 1:'D', 2:'A'}\n",
    "test_report = pd.DataFrame({'Date':test_df2.Date, \\\n",
    "                       'HomeTeam':test_df2.HomeTeam, \\\n",
    "                       'AwayTeam':test_df2.AwayTeam, \\\n",
    "                       'True Outcome':test_df2.FTR.tolist(), \\\n",
    "                       'Predicted Outcome': [trans[res] for res in gs.predict(test_X)], \\\n",
    "                       'H':test_df2.B365H,\\\n",
    "                       'D':test_df2.B365D,\\\n",
    "                       'A':test_df2.B365A\\\n",
    "                      }, columns=['Date', 'HomeTeam', 'AwayTeam', 'True Outcome', 'Predicted Outcome', 'H', 'D', 'A'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>True Outcome</th>\n",
       "      <th>Predicted Outcome</th>\n",
       "      <th>H</th>\n",
       "      <th>D</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0  </th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>    Bournemouth</td>\n",
       "      <td>    Aston Villa</td>\n",
       "      <td> A</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.00</td>\n",
       "      <td> 3.60</td>\n",
       "      <td>  4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1  </th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>        Chelsea</td>\n",
       "      <td>        Swansea</td>\n",
       "      <td> D</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.36</td>\n",
       "      <td> 5.00</td>\n",
       "      <td> 11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2  </th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>        Everton</td>\n",
       "      <td>        Watford</td>\n",
       "      <td> D</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.70</td>\n",
       "      <td> 3.90</td>\n",
       "      <td>  5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3  </th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>      Leicester</td>\n",
       "      <td>     Sunderland</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.95</td>\n",
       "      <td> 3.50</td>\n",
       "      <td>  4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4  </th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>     Man United</td>\n",
       "      <td>      Tottenham</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.65</td>\n",
       "      <td> 4.00</td>\n",
       "      <td>  6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5  </th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>        Norwich</td>\n",
       "      <td> Crystal Palace</td>\n",
       "      <td> A</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.55</td>\n",
       "      <td> 3.30</td>\n",
       "      <td>  3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6  </th>\n",
       "      <td>2015-08-09</td>\n",
       "      <td>        Arsenal</td>\n",
       "      <td>       West Ham</td>\n",
       "      <td> A</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.29</td>\n",
       "      <td> 6.00</td>\n",
       "      <td> 12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7  </th>\n",
       "      <td>2015-08-09</td>\n",
       "      <td>      Newcastle</td>\n",
       "      <td>    Southampton</td>\n",
       "      <td> D</td>\n",
       "      <td> A</td>\n",
       "      <td> 2.88</td>\n",
       "      <td> 3.30</td>\n",
       "      <td>  2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8  </th>\n",
       "      <td>2015-08-09</td>\n",
       "      <td>          Stoke</td>\n",
       "      <td>      Liverpool</td>\n",
       "      <td> A</td>\n",
       "      <td> H</td>\n",
       "      <td> 3.40</td>\n",
       "      <td> 3.40</td>\n",
       "      <td>  2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9  </th>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>      West Brom</td>\n",
       "      <td>       Man City</td>\n",
       "      <td> A</td>\n",
       "      <td> A</td>\n",
       "      <td> 5.75</td>\n",
       "      <td> 4.00</td>\n",
       "      <td>  1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 </th>\n",
       "      <td>2015-08-14</td>\n",
       "      <td>    Aston Villa</td>\n",
       "      <td>     Man United</td>\n",
       "      <td> A</td>\n",
       "      <td> A</td>\n",
       "      <td> 5.50</td>\n",
       "      <td> 3.80</td>\n",
       "      <td>  1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11 </th>\n",
       "      <td>2015-08-15</td>\n",
       "      <td>    Southampton</td>\n",
       "      <td>        Everton</td>\n",
       "      <td> A</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.95</td>\n",
       "      <td> 3.60</td>\n",
       "      <td>  4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 </th>\n",
       "      <td>2015-08-15</td>\n",
       "      <td>     Sunderland</td>\n",
       "      <td>        Norwich</td>\n",
       "      <td> A</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.50</td>\n",
       "      <td> 3.30</td>\n",
       "      <td>  3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13 </th>\n",
       "      <td>2015-08-15</td>\n",
       "      <td>        Swansea</td>\n",
       "      <td>      Newcastle</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.95</td>\n",
       "      <td> 3.60</td>\n",
       "      <td>  4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14 </th>\n",
       "      <td>2015-08-15</td>\n",
       "      <td>      Tottenham</td>\n",
       "      <td>          Stoke</td>\n",
       "      <td> D</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.80</td>\n",
       "      <td> 3.75</td>\n",
       "      <td>  5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15 </th>\n",
       "      <td>2015-08-15</td>\n",
       "      <td>        Watford</td>\n",
       "      <td>      West Brom</td>\n",
       "      <td> D</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.30</td>\n",
       "      <td> 3.40</td>\n",
       "      <td>  3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16 </th>\n",
       "      <td>2015-08-15</td>\n",
       "      <td>       West Ham</td>\n",
       "      <td>      Leicester</td>\n",
       "      <td> A</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.25</td>\n",
       "      <td> 3.50</td>\n",
       "      <td>  3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17 </th>\n",
       "      <td>2015-08-16</td>\n",
       "      <td> Crystal Palace</td>\n",
       "      <td>        Arsenal</td>\n",
       "      <td> A</td>\n",
       "      <td> A</td>\n",
       "      <td> 5.25</td>\n",
       "      <td> 3.90</td>\n",
       "      <td>  1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18 </th>\n",
       "      <td>2015-08-16</td>\n",
       "      <td>       Man City</td>\n",
       "      <td>        Chelsea</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.10</td>\n",
       "      <td> 3.50</td>\n",
       "      <td>  3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19 </th>\n",
       "      <td>2015-08-17</td>\n",
       "      <td>      Liverpool</td>\n",
       "      <td>    Bournemouth</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.45</td>\n",
       "      <td> 4.75</td>\n",
       "      <td>  8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20 </th>\n",
       "      <td>2015-08-22</td>\n",
       "      <td> Crystal Palace</td>\n",
       "      <td>    Aston Villa</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.85</td>\n",
       "      <td> 3.60</td>\n",
       "      <td>  4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21 </th>\n",
       "      <td>2015-08-22</td>\n",
       "      <td>      Leicester</td>\n",
       "      <td>      Tottenham</td>\n",
       "      <td> D</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.63</td>\n",
       "      <td> 3.60</td>\n",
       "      <td>  2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22 </th>\n",
       "      <td>2015-08-22</td>\n",
       "      <td>     Man United</td>\n",
       "      <td>      Newcastle</td>\n",
       "      <td> D</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.36</td>\n",
       "      <td> 5.25</td>\n",
       "      <td> 10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23 </th>\n",
       "      <td>2015-08-22</td>\n",
       "      <td>        Norwich</td>\n",
       "      <td>          Stoke</td>\n",
       "      <td> D</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.30</td>\n",
       "      <td> 3.30</td>\n",
       "      <td>  3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24 </th>\n",
       "      <td>2015-08-22</td>\n",
       "      <td>     Sunderland</td>\n",
       "      <td>        Swansea</td>\n",
       "      <td> D</td>\n",
       "      <td> A</td>\n",
       "      <td> 4.00</td>\n",
       "      <td> 3.40</td>\n",
       "      <td>  2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25 </th>\n",
       "      <td>2015-08-22</td>\n",
       "      <td>       West Ham</td>\n",
       "      <td>    Bournemouth</td>\n",
       "      <td> A</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.38</td>\n",
       "      <td> 3.40</td>\n",
       "      <td>  3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26 </th>\n",
       "      <td>2015-08-23</td>\n",
       "      <td>        Everton</td>\n",
       "      <td>       Man City</td>\n",
       "      <td> A</td>\n",
       "      <td> A</td>\n",
       "      <td> 5.00</td>\n",
       "      <td> 4.00</td>\n",
       "      <td>  1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27 </th>\n",
       "      <td>2015-08-23</td>\n",
       "      <td>        Watford</td>\n",
       "      <td>    Southampton</td>\n",
       "      <td> D</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.80</td>\n",
       "      <td> 3.30</td>\n",
       "      <td>  2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28 </th>\n",
       "      <td>2015-08-23</td>\n",
       "      <td>      West Brom</td>\n",
       "      <td>        Chelsea</td>\n",
       "      <td> A</td>\n",
       "      <td> A</td>\n",
       "      <td> 6.50</td>\n",
       "      <td> 4.00</td>\n",
       "      <td>  1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29 </th>\n",
       "      <td>2015-08-24</td>\n",
       "      <td>        Arsenal</td>\n",
       "      <td>      Liverpool</td>\n",
       "      <td> D</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.75</td>\n",
       "      <td> 4.00</td>\n",
       "      <td>  5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80 </th>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>        Chelsea</td>\n",
       "      <td>    Aston Villa</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.33</td>\n",
       "      <td> 5.75</td>\n",
       "      <td> 10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81 </th>\n",
       "      <td>2015-10-17</td>\n",
       "      <td> Crystal Palace</td>\n",
       "      <td>       West Ham</td>\n",
       "      <td> A</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.00</td>\n",
       "      <td> 3.60</td>\n",
       "      <td>  4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82 </th>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>        Everton</td>\n",
       "      <td>     Man United</td>\n",
       "      <td> A</td>\n",
       "      <td> A</td>\n",
       "      <td> 3.25</td>\n",
       "      <td> 3.40</td>\n",
       "      <td>  2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83 </th>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>       Man City</td>\n",
       "      <td>    Bournemouth</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.33</td>\n",
       "      <td> 5.75</td>\n",
       "      <td> 10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84 </th>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>    Southampton</td>\n",
       "      <td>      Leicester</td>\n",
       "      <td> D</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.75</td>\n",
       "      <td> 4.00</td>\n",
       "      <td>  5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85 </th>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>      Tottenham</td>\n",
       "      <td>      Liverpool</td>\n",
       "      <td> D</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.50</td>\n",
       "      <td> 3.50</td>\n",
       "      <td>  3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86 </th>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>        Watford</td>\n",
       "      <td>        Arsenal</td>\n",
       "      <td> A</td>\n",
       "      <td> A</td>\n",
       "      <td> 6.00</td>\n",
       "      <td> 4.20</td>\n",
       "      <td>  1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87 </th>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>      West Brom</td>\n",
       "      <td>     Sunderland</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.05</td>\n",
       "      <td> 3.40</td>\n",
       "      <td>  4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88 </th>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>      Newcastle</td>\n",
       "      <td>        Norwich</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.60</td>\n",
       "      <td> 3.40</td>\n",
       "      <td>  2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89 </th>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>        Swansea</td>\n",
       "      <td>          Stoke</td>\n",
       "      <td> A</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.05</td>\n",
       "      <td> 3.40</td>\n",
       "      <td>  4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90 </th>\n",
       "      <td>2015-10-24</td>\n",
       "      <td>        Arsenal</td>\n",
       "      <td>        Everton</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.44</td>\n",
       "      <td> 4.75</td>\n",
       "      <td>  8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91 </th>\n",
       "      <td>2015-10-24</td>\n",
       "      <td>    Aston Villa</td>\n",
       "      <td>        Swansea</td>\n",
       "      <td> A</td>\n",
       "      <td> A</td>\n",
       "      <td> 3.00</td>\n",
       "      <td> 3.30</td>\n",
       "      <td>  2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92 </th>\n",
       "      <td>2015-10-24</td>\n",
       "      <td>      Leicester</td>\n",
       "      <td> Crystal Palace</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.20</td>\n",
       "      <td> 3.60</td>\n",
       "      <td>  3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93 </th>\n",
       "      <td>2015-10-24</td>\n",
       "      <td>        Norwich</td>\n",
       "      <td>      West Brom</td>\n",
       "      <td> A</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.00</td>\n",
       "      <td> 3.50</td>\n",
       "      <td>  4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94 </th>\n",
       "      <td>2015-10-24</td>\n",
       "      <td>          Stoke</td>\n",
       "      <td>        Watford</td>\n",
       "      <td> A</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.10</td>\n",
       "      <td> 3.30</td>\n",
       "      <td>  4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95 </th>\n",
       "      <td>2015-10-24</td>\n",
       "      <td>       West Ham</td>\n",
       "      <td>        Chelsea</td>\n",
       "      <td> H</td>\n",
       "      <td> A</td>\n",
       "      <td> 4.00</td>\n",
       "      <td> 3.80</td>\n",
       "      <td>  1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96 </th>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>    Bournemouth</td>\n",
       "      <td>      Tottenham</td>\n",
       "      <td> A</td>\n",
       "      <td> A</td>\n",
       "      <td> 3.40</td>\n",
       "      <td> 3.50</td>\n",
       "      <td>  2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97 </th>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>      Liverpool</td>\n",
       "      <td>    Southampton</td>\n",
       "      <td> D</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.05</td>\n",
       "      <td> 3.60</td>\n",
       "      <td>  3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98 </th>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>     Man United</td>\n",
       "      <td>       Man City</td>\n",
       "      <td> D</td>\n",
       "      <td> A</td>\n",
       "      <td> 2.60</td>\n",
       "      <td> 3.50</td>\n",
       "      <td>  2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99 </th>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>     Sunderland</td>\n",
       "      <td>      Newcastle</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.60</td>\n",
       "      <td> 3.40</td>\n",
       "      <td>  2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2015-10-31</td>\n",
       "      <td>        Chelsea</td>\n",
       "      <td>      Liverpool</td>\n",
       "      <td> A</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.10</td>\n",
       "      <td> 3.50</td>\n",
       "      <td>  3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2015-10-31</td>\n",
       "      <td> Crystal Palace</td>\n",
       "      <td>     Man United</td>\n",
       "      <td> D</td>\n",
       "      <td> A</td>\n",
       "      <td> 3.80</td>\n",
       "      <td> 3.50</td>\n",
       "      <td>  2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2015-10-31</td>\n",
       "      <td>       Man City</td>\n",
       "      <td>        Norwich</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.29</td>\n",
       "      <td> 6.00</td>\n",
       "      <td> 12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2015-10-31</td>\n",
       "      <td>      Newcastle</td>\n",
       "      <td>          Stoke</td>\n",
       "      <td> D</td>\n",
       "      <td> H</td>\n",
       "      <td> 2.40</td>\n",
       "      <td> 3.40</td>\n",
       "      <td>  3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2015-10-31</td>\n",
       "      <td>        Swansea</td>\n",
       "      <td>        Arsenal</td>\n",
       "      <td> A</td>\n",
       "      <td> A</td>\n",
       "      <td> 5.00</td>\n",
       "      <td> 4.00</td>\n",
       "      <td>  1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2015-10-31</td>\n",
       "      <td>        Watford</td>\n",
       "      <td>       West Ham</td>\n",
       "      <td> H</td>\n",
       "      <td> A</td>\n",
       "      <td> 2.60</td>\n",
       "      <td> 3.40</td>\n",
       "      <td>  2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2015-10-31</td>\n",
       "      <td>      West Brom</td>\n",
       "      <td>      Leicester</td>\n",
       "      <td> A</td>\n",
       "      <td> D</td>\n",
       "      <td> 2.90</td>\n",
       "      <td> 3.40</td>\n",
       "      <td>  2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>        Everton</td>\n",
       "      <td>     Sunderland</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.50</td>\n",
       "      <td> 4.50</td>\n",
       "      <td>  7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>    Southampton</td>\n",
       "      <td>    Bournemouth</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.55</td>\n",
       "      <td> 4.33</td>\n",
       "      <td>  6.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>      Tottenham</td>\n",
       "      <td>    Aston Villa</td>\n",
       "      <td> H</td>\n",
       "      <td> H</td>\n",
       "      <td> 1.44</td>\n",
       "      <td> 4.75</td>\n",
       "      <td>  8.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        HomeTeam        AwayTeam True Outcome Predicted Outcome  \\\n",
       "0   2015-08-08     Bournemouth     Aston Villa            A                 H   \n",
       "1   2015-08-08         Chelsea         Swansea            D                 H   \n",
       "2   2015-08-08         Everton         Watford            D                 H   \n",
       "3   2015-08-08       Leicester      Sunderland            H                 H   \n",
       "4   2015-08-08      Man United       Tottenham            H                 H   \n",
       "5   2015-08-08         Norwich  Crystal Palace            A                 H   \n",
       "6   2015-08-09         Arsenal        West Ham            A                 H   \n",
       "7   2015-08-09       Newcastle     Southampton            D                 A   \n",
       "8   2015-08-09           Stoke       Liverpool            A                 H   \n",
       "9   2015-08-10       West Brom        Man City            A                 A   \n",
       "10  2015-08-14     Aston Villa      Man United            A                 A   \n",
       "11  2015-08-15     Southampton         Everton            A                 H   \n",
       "12  2015-08-15      Sunderland         Norwich            A                 H   \n",
       "13  2015-08-15         Swansea       Newcastle            H                 H   \n",
       "14  2015-08-15       Tottenham           Stoke            D                 H   \n",
       "15  2015-08-15         Watford       West Brom            D                 H   \n",
       "16  2015-08-15        West Ham       Leicester            A                 H   \n",
       "17  2015-08-16  Crystal Palace         Arsenal            A                 A   \n",
       "18  2015-08-16        Man City         Chelsea            H                 H   \n",
       "19  2015-08-17       Liverpool     Bournemouth            H                 H   \n",
       "20  2015-08-22  Crystal Palace     Aston Villa            H                 H   \n",
       "21  2015-08-22       Leicester       Tottenham            D                 H   \n",
       "22  2015-08-22      Man United       Newcastle            D                 H   \n",
       "23  2015-08-22         Norwich           Stoke            D                 H   \n",
       "24  2015-08-22      Sunderland         Swansea            D                 A   \n",
       "25  2015-08-22        West Ham     Bournemouth            A                 H   \n",
       "26  2015-08-23         Everton        Man City            A                 A   \n",
       "27  2015-08-23         Watford     Southampton            D                 H   \n",
       "28  2015-08-23       West Brom         Chelsea            A                 A   \n",
       "29  2015-08-24         Arsenal       Liverpool            D                 H   \n",
       "..         ...             ...             ...          ...               ...   \n",
       "80  2015-10-17         Chelsea     Aston Villa            H                 H   \n",
       "81  2015-10-17  Crystal Palace        West Ham            A                 H   \n",
       "82  2015-10-17         Everton      Man United            A                 A   \n",
       "83  2015-10-17        Man City     Bournemouth            H                 H   \n",
       "84  2015-10-17     Southampton       Leicester            D                 H   \n",
       "85  2015-10-17       Tottenham       Liverpool            D                 H   \n",
       "86  2015-10-17         Watford         Arsenal            A                 A   \n",
       "87  2015-10-17       West Brom      Sunderland            H                 H   \n",
       "88  2015-10-18       Newcastle         Norwich            H                 H   \n",
       "89  2015-10-19         Swansea           Stoke            A                 H   \n",
       "90  2015-10-24         Arsenal         Everton            H                 H   \n",
       "91  2015-10-24     Aston Villa         Swansea            A                 A   \n",
       "92  2015-10-24       Leicester  Crystal Palace            H                 H   \n",
       "93  2015-10-24         Norwich       West Brom            A                 H   \n",
       "94  2015-10-24           Stoke         Watford            A                 H   \n",
       "95  2015-10-24        West Ham         Chelsea            H                 A   \n",
       "96  2015-10-25     Bournemouth       Tottenham            A                 A   \n",
       "97  2015-10-25       Liverpool     Southampton            D                 H   \n",
       "98  2015-10-25      Man United        Man City            D                 A   \n",
       "99  2015-10-25      Sunderland       Newcastle            H                 H   \n",
       "100 2015-10-31         Chelsea       Liverpool            A                 H   \n",
       "101 2015-10-31  Crystal Palace      Man United            D                 A   \n",
       "102 2015-10-31        Man City         Norwich            H                 H   \n",
       "103 2015-10-31       Newcastle           Stoke            D                 H   \n",
       "104 2015-10-31         Swansea         Arsenal            A                 A   \n",
       "105 2015-10-31         Watford        West Ham            H                 A   \n",
       "106 2015-10-31       West Brom       Leicester            A                 D   \n",
       "107 2015-11-01         Everton      Sunderland            H                 H   \n",
       "108 2015-11-01     Southampton     Bournemouth            H                 H   \n",
       "109 2015-11-02       Tottenham     Aston Villa            H                 H   \n",
       "\n",
       "        H     D      A  \n",
       "0    2.00  3.60   4.00  \n",
       "1    1.36  5.00  11.00  \n",
       "2    1.70  3.90   5.50  \n",
       "3    1.95  3.50   4.33  \n",
       "4    1.65  4.00   6.00  \n",
       "5    2.55  3.30   3.00  \n",
       "6    1.29  6.00  12.00  \n",
       "7    2.88  3.30   2.70  \n",
       "8    3.40  3.40   2.30  \n",
       "9    5.75  4.00   1.67  \n",
       "10   5.50  3.80   1.73  \n",
       "11   1.95  3.60   4.33  \n",
       "12   2.50  3.30   3.10  \n",
       "13   1.95  3.60   4.33  \n",
       "14   1.80  3.75   5.00  \n",
       "15   2.30  3.40   3.40  \n",
       "16   2.25  3.50   3.40  \n",
       "17   5.25  3.90   1.73  \n",
       "18   2.10  3.50   3.75  \n",
       "19   1.45  4.75   8.00  \n",
       "20   1.85  3.60   4.75  \n",
       "21   2.63  3.60   2.75  \n",
       "22   1.36  5.25  10.00  \n",
       "23   2.30  3.30   3.50  \n",
       "24   4.00  3.40   2.10  \n",
       "25   2.38  3.40   3.20  \n",
       "26   5.00  4.00   1.73  \n",
       "27   2.80  3.30   2.75  \n",
       "28   6.50  4.00   1.62  \n",
       "29   1.75  4.00   5.00  \n",
       "..    ...   ...    ...  \n",
       "80   1.33  5.75  10.00  \n",
       "81   2.00  3.60   4.00  \n",
       "82   3.25  3.40   2.38  \n",
       "83   1.33  5.75  10.00  \n",
       "84   1.75  4.00   5.00  \n",
       "85   2.50  3.50   3.00  \n",
       "86   6.00  4.20   1.62  \n",
       "87   2.05  3.40   4.20  \n",
       "88   2.60  3.40   2.88  \n",
       "89   2.05  3.40   4.20  \n",
       "90   1.44  4.75   8.00  \n",
       "91   3.00  3.30   2.60  \n",
       "92   2.20  3.60   3.40  \n",
       "93   2.00  3.50   4.20  \n",
       "94   2.10  3.30   4.00  \n",
       "95   4.00  3.80   1.95  \n",
       "96   3.40  3.50   2.25  \n",
       "97   2.05  3.60   3.80  \n",
       "98   2.60  3.50   2.80  \n",
       "99   2.60  3.40   2.90  \n",
       "100  2.10  3.50   3.75  \n",
       "101  3.80  3.50   2.10  \n",
       "102  1.29  6.00  12.00  \n",
       "103  2.40  3.40   3.20  \n",
       "104  5.00  4.00   1.75  \n",
       "105  2.60  3.40   2.90  \n",
       "106  2.90  3.40   2.60  \n",
       "107  1.50  4.50   7.50  \n",
       "108  1.55  4.33   6.50  \n",
       "109  1.44  4.75   8.00  \n",
       "\n",
       "[110 rows x 8 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJztnXnUnWV57n8XUwhjEgIhgcAHkQwgoKhIBSXGoCgsoLqq\n",
       "4lDAKl3Vo1RbMehRaY8DoK22Vo6HlpAoilWOJw3gkJRJLFZlCIQhBNRIIMkXhgSCEMb7/PE+G3Z2\n",
       "9vgO+53u31p7fft5x+fOfnPte1/PJDPDcRzHqTbb5F0Bx3EcJ3tc7B3HcWqAi73jOE4NcLF3HMep\n",
       "AS72juM4NcDF3nEcpwZ0FXtJ8yWNSlretG2CpKWSVkpaImlc077DJP1S0h2Sbpc0JsvKO47jOP3R\n",
       "K7O/BDi+Zds8YKmZTQeuDmUkbQd8BzjTzF4OHAs8m251HcdxnDh0FXszuwHY0LL5JGBheL8QOCW8\n",
       "fzNwu5ktD+duMLMXUqyr4ziOE5M4nv0kMxsN70eBSeH9dMAk/VTSzZI+mUoNHcdxnMRsl+RkMzNJ\n",
       "jfkWtgOOAV4NPAVcLelmM7smYR0dx3GchMQR+1FJe5vZOkmTgfVh+2rg52b2KICkHwNHAFuJfdMX\n",
       "hOM4jtMnZqa458YR+8XAacD54e+isH0JcLaksUQNs8cC/9jpIkkqXWQknWtm5+Zdj6zw+MqNx1de\n",
       "kibJvbpeXgbcCMyQtFrSGcB5wHGSVgJzQhkz20Ak7r8BbgVuNrOfJKlcSRnJuwIZM5J3BTJmJO8K\n",
       "ZMxI3hXImJG8K1BUumb2ZnZqh11zOxz/XeC7SSvlOI7jpIuPoE2fBXlXIGMW5F2BjFmQdwUyZkHe\n",
       "FciYBXlXoKgoj8VLJFlVPXvHcZwsSKqbntmnjKTZedchSzy+cuPx1RcXe8dxnBrgNo7jOE4JcBvH\n",
       "cRzH6YmLfcpU3TP0+MqNx1dfXOwdx3FqgHv2juM4JSCpbiaa9dJxHCdLJPYCGivePWrGH/OsT5lx\n",
       "Gydlqu4ZenzlpkzxSewJPEg0P9ctwPd7n1Oe+IaNi73jOEVlb2CFGVOB44D9c65PqXHP3nGcQiIx\n",
       "B/isGW8Mds6dZuyZd73ywvvZO45TVSYCD4X3DwO7S+yQY31KjYt9ylTdM/T4yk3J4tuTSOQx4wWi\n",
       "Na/37nZCyeIbKi72juMUlebMHmAtMCWnupQe73qZMmZ2Xd51yBKPr9zkFZ/EZGCnLocYsCpk8A32\n",
       "BO5pKq+hh9hX/fNLgou94ziZIrEz8AdgdZfD9gI+APywadtE4BdN5bXA5NQrWBPcxkmZqnuGHl+5\n",
       "ySm+8cB6M6Z1egH/CuzXct6Lnn2gZ2Zf9c8vCb0WHJ8vaVTS8qZtEyQtlbRS0hJJ48L2EUlPSbo1\n",
       "vC7MuvKO45SCccDGHse08+MnsrXYe2Yfk16Z/SXA8S3b5gFLzWw6cHUoN7jPzF4ZXh9OsZ6loeqe\n",
       "ocdXbnKKrx+xbyfkezJgA23VP78kdBV7M7sB2NCy+SRgYXi/EDglg3o5jlMdBs7sJUT7zN5748Qk\n",
       "jmc/ycxGw/tRYFLTvgOChXOdpGOSV698VN0z9PjKTU7x9ZvZNwv5bsBmM55u2tazgbbqn18SEvXG\n",
       "MTOT1JhvYQ0w1cw2SDoCWCTpEDPblLiWjuOUmTg2TmtWD5Gls7vEDmY8k2L9akEcsR+VtLeZrZM0\n",
       "GVgPYGbPQPQBmNktkn4LHEQ0W91WSFoArArFjcCyht/W+HYuY9nMritSfTw+jy/v+OBbr4Rtd4AP\n",
       "0fn4bYDnt5HYFfQq+NDBcNFDrcdLrIc3nSJds74o8WVVDswGRkiBnhOhSRoBrjCzQ0P5AuARMztf\n",
       "0jxgnJnNkzQR2GBmz0s6EPg58HIz2+ob3SdCc5z6IPFVYJ0ZX+1x3L3ACWaslDgR+CszTmg55tfA\n",
       "x8z47+xqXEwynQhN0mVEc0nPkLRa0hnAecBxklYCc0IZ4A3AbZJuJRoY8ZfthL7qVN0z9PjKTYE9\n",
       "e9iykba1J06Dro20Vf/8ktDVxjGzUzvsmtvm2B8BP0qjUo7jVIp+xb5ZyNt59uCjaGPjI2hTpur9\n",
       "fD2+clPgfvawZSNtrMy+6p9fElzsHcfJmnHAY30c12zjdMvsva99DFzsU6bqnqHHV24K7tm3Zvbt\n",
       "xL7rlAlV//yS4GLvOE7WxPXs29k4ntnHxNegdRwnM8K0B88CO/UaCCUxE1hsxnSJ+4C3mbGy5ZhJ\n",
       "wB11XIs2066XjuM4CdkZeLrPEa/NFk2nzL4xinZMSvWrDS72KVN1z9DjKzc5xNevhQOwCdhGYg+i\n",
       "L4mtGnXDSlbr6bAWbdU/vyS42DuOkyV9i70ZRpTdHwo80rJEYTM+r30MXOxTpur9fD2+cpNDfINk\n",
       "9hAJ+WG074nToGMjbdU/vyT4GrSO42TJoGK/lkjs2/n1DdYAR0k82LL9STOWtzvB8cw+daruGXp8\n",
       "5abgnj28ZON0y+yvBY4F/rnldZN01Ntj1rPyeGbvOE6WxMnsDwVu7nSAGT8AftC6XeJWmDlx4BrW\n",
       "BM/sU6bqnqHHV25K4tmPpXtm34m1sGBtjPNqgYu94zhZEkfsobtn3+1c76XTARf7lHHPt9x4fKkT\n",
       "x8aB2Jn9Ra+LcV4tcLF3HCdL4mb2ccR+Dew0IcZ5tcDFPmXc8y03Hl/qDCr2m4AniW3jvK+vuWMk\n",
       "pkj10r9aBes4ztAZSOzDKNr/A/wuxr0GWcXqP4i6b9YGF/uUcc+33Hh8qTNoZo8ZnzDj8Rj3WgNL\n",
       "RnodFGbinA7sG+MepaXXguPzJY1KWt60bYKkpZJWSloiaVzLOftJekLS32RVacdxSsPAYp+AUdh+\n",
       "nMS2PY4bD+xGzXru9MrsLwGOb9k2D1hqZtOBq0O5mX8ErkqneuXDPd9y4/GlR8ig+12SMDFmPAtv\n",
       "fATYq8ehB4a/tVoEpavYm9kNwIaWzScBC8P7hcApjR2STiHy2u5KsY6O45STQeayT4uuC5IHDgSe\n",
       "wzP7nkwys9HwfhSYBCBpF+Bs4Nx0qlZO3PMtNx5fqgzTwgn86Gl6i/g04BZqltknmhvHzExSY13D\n",
       "c4GvmdmTknp2f5K0AFgVihuBZY2fmI0H0ste9nJ5y2APAxuHe/+nHoGvzJbOfqLT8fDdo+GZVXDG\n",
       "q4v077X1vx8As4ERUqDnGrSSRoArzOzQUF4BzDazdZImA9ea2UxJPwemhtPGAS8AnzWzC9tc09eg\n",
       "dZyKI3EMcL4ZRw/xnn8PPG/G33U55mrgm8ClwM6hu2fhSaqbcTL7xcBpwPnh7yIAM3tDU6U+D2xq\n",
       "J/SO49SGHGwc1gKv6HHMgcDtRL797gy/jrnQq+vlZcCNwAxJqyWdAZwHHCdpJTAnlJ2Ae77lxuNL\n",
       "lRzE/jMT6OLFS2wf9t/PYIOwSk/XzN7MTu2wa26P8zr+hHIcpzbkIPbrHqG7gO8HrDHjGenFnjt3\n",
       "D6VqOeMjaFPG+2mXG48vVXIQ+4uvpHsvmwN5aSqGWk2J7GLvOE5W5OHZjwITu4yibRb7jguXVxEX\n",
       "+5Rxz7fceHypkkPjp44mGgjaaRRta2bvYu84jpOQPDJ76G7PtGb2buM48XDPt9x4fKkydLEP8XWz\n",
       "Z6ZR08w+0Qhax3HqhcRHgX5Xg5pFfpn9ViIeJmZrFXvP7J14uOdbbjy+bucyEfgykW708/oWcGey\n",
       "Gg9aR82ms4iPD38fDX/XAlPCl0Dl8czecZx+mQXcYcbn865IDzqNoj0Q+F1jegQznpB4jmhu+6FM\n",
       "w5wnntmnjHu+5cbj68osCj59eYivU2Z/IPDblm216X7pmb3jOP0yi3KMNl0LzJReWmsj8Fa2Xtu2\n",
       "NqNoPbNPGfd8y43H15WDKbgohvhWAMuA01te44ErW06pTSOtZ/aO4/RL4W0cgLBY+Tv7PLw2Nk7P\n",
       "+ewzuanPZ+84pUJiF2A9sKsZz+ddn7SQ+AQw1YyP512XXiTVTbdxHMfph5nAyioJfaA2mb2Lfcq4\n",
       "51tuPL6OFN6vh1jx1cazd7F3HKcfSuHXx6A2Uya4Z+84Tk8kFgGXmnF53nVJk9AW8RBRb51++ZnZ\n",
       "8KeByGMNWsdx6kdZ+tgPRBhFezHw9gFO+xUlXLfWM/uUkTS7yqMwPb5yEyc+iTFE0wnsZsYzmVQs\n",
       "Jar8+WXaG0fSfEmjkpY3bZsgaamklZKWSBoXth8p6dbwul3Su+JWynGcQnEQsKroQu90p2tmL+n1\n",
       "wBPAt83s0LDtAuBhM7tA0qeA8WY2T9JY4Gkze0HS3sAdwCQz26qrVpUze8epGhJ/BrzHjD/Nuy51\n",
       "JtPM3sxuIFriq5mTgIXh/UKI5p8ws6fM7IWwfSzwWDuhdxyndFS1J06tiNP1cpKZjYb3o8Ckxo5g\n",
       "5dxJNIf1J1KoX+nwftrlpm7xSUjiUIlXdXoBR1GSxtmqf35JSNQbx8xMkjWVfw0cImkm8FNJ15lZ\n",
       "23miJS0AVoXiRmBZo2Gl8YF52ctezrx8EFxzEzy1Ck54AgCu2iX62yhfuRP87xfgKgpQ39qUA7OB\n",
       "EVKgZ28cSSPAFU2e/QpgtpmtkzQZuNbMZrY572rgbDO7uc0+9+wdpwBIvB44z4yj866L051MPfsO\n",
       "LAZOC+9PAxaFioxI2i6835+oBf/euBVzHGcoTAAeybsSTvb06np5GXAjMEPSaklnAOcBx0laCcwJ\n",
       "ZYBjgGWSbgV+CJxpZo9nV/ViUnXP0OMrN23i24OX1mQtPVX//JLQ1bM3s1M77Jrb5thLgUvTqJTj\n",
       "OEPDM/ua4CNoHafGSHwZeMKML+ZdF6c7eXj2juNUB8/sa4KLfcpU3TP0+MpNB8++MmJf9c8vCS72\n",
       "jlNvJlChBlqnM+7ZO06NkbgNOM2MZXnXxelOUt30+ewdJyckTgJOiHGqAReY8bsUquGZfU1wsU8Z\n",
       "VXg+bfD4UuY9wCbgpgHPex/wRhhc7NvEVznPvsrPZxJc7B0nP3YhWurvykFOktifFNZNlRgLbAs8\n",
       "mfRaTvHxBtqUqXpW4fGlyq5E60UMyhpgcpwbtsQ3AXjEjOE33GVE1Z/PJLjYO05+7EJ8sU+c2VOx\n",
       "qRKc7rjYp0zV+/l6fKkSV+zXElPsW+Kr3ICqqj+fSXCxd5z82IWogXZQYts4LVSqcdbpjvezd5yc\n",
       "kHgM2M+Mtgv8dDlvDNGXxI5mvNDr+C7X+RDwWjM+GPcazvDwuXEcp4RIiCiz/+Og55rxNPA4MDFh\n",
       "NTyzrxEu9ilTdc/Q40uNscAzZjwX8/xYjbRtPPtKNdBW/flMgou94+RD3MbZBmtJ7tt7Zl8jXOxT\n",
       "pur9fD2+1Egq9rEy+zb97CuV2Vf9+UyCi73j5EPcnjgN0uhr75l9jXCxT5mqe4YeX2rkYuN4P/v6\n",
       "0lPsJc2XNCppedO2CZKWSlopaYmkcWH7cZJuknR7+PvGLCvvxENCEntKTOryGp93PStO3KkSGqSV\n",
       "2VfKxnE607OfvaTXEz2U3zazQ8O2C4CHzewCSZ8CxpvZPEmvANaZ2TpJhwA/M7N921zT+9nniMRb\n",
       "gP+Arv27JwD7mjE6nFrVC4l3AO814+0xz/8T4OtmvDbm+QI2A7ubsTnONZzhknk/ezO7AdjQsvkk\n",
       "YGF4vxA4JRy7zMzWhe13AWMlbR+3ck5mHA5caMakTi9gObBfzvWsMrk00DaxM/CcC319iOvZTzKz\n",
       "RsY3Ckxqc8w7gJvN7NmY9yglJfEMZwF39zim7ZD8ksQXmyF79kkaaNcBk6TB/g83xVfJxtmqP59J\n",
       "SDyfvZmZpC28oGDhnAcc1+k8SQuAVaG4EVjW6DbV+MC8nE0Zrnwt/PgWuJDOx19q8N4pRahvNcv/\n",
       "chh8ZGOS64E9DkyUdPDg57//ZfDtR4vz7+HlrT9fAGYDI6RAX3PjSBoBrmjy7FcAs4M3Pxm41sxm\n",
       "hn37AlcDp5vZLztczz37nAhe7WPAAWadMzuJvwNkxueGVrkaIfEF4Gkz/leCa9wO/Hmc9WMl5gLn\n",
       "mPGmuPd3hktec+MsBk4L708DFoXKjAOuAj7VSeid3JkCPNVN6ANpzazotCepZw/JRtFWbkCV051+\n",
       "ul5eBtwIzJC0WtIZBItG0kpgTigD/A9gGvB5SbeGV9LJmkpFCTzDg+nt10OHOdNLEF8ihuzZJxX7\n",
       "gRtp3bOvLz09ezM7tcOuuW2O/QLwhaSVcjKln8ZZ8Mw+a9IS+ySZfeXE3umMj6BNmRLMzTGLqFts\n",
       "L9pmjSWILxFDnhsnSW8ciLFiVVN8lRxQVfXnMwku9vWjXxtnPbCH1P7Xn8RfSbwr1ZrVi1xsnCY8\n",
       "s68ZLvYpUwLPsC8bJ8yz/jAtYyia4psL8UZvFpkhfn5Jp0uAGA20LZ595TL7Evz/yw0X+xohsQcw\n",
       "higj7IdumeN03NNPgmf2zlBJPKjK2ZKCe4azgLvN6Hfh4a0yRzO7TmJb4CAqmBmWaD57aBpF2+9a\n",
       "tO7Z1xcX+3rRr1/foFPmOBXYHs/sk5C4gdaMpyU2AldJAy9vOEJk0zk1wcU+ZSTNLnB20W+3ywZb\n",
       "ZfaRJ2o7ALcAsyQ0wC+FwjOMzy/JYuNteBsDfeme83L48h3A18x4KIX7F4qC///LFRf7ejGLaCqL\n",
       "flkDvLrN9unATeF6uwKPJ69arUi62PiLmHHTIMdL520y+/J1Se/rlA9voE2ZgmcViW2cEN90YCUV\n",
       "HHg1pM8vDb8+FgV/PhNT9fiS4Jl9SZD4JnBkwstM4KWZRvuhU9e+GcDPeOnL4J6E9aobuYm9U19c\n",
       "7FMmC88weLzvI1okJolIbDDj+QGO3yqzD559I7NPMhFXIRmS55ub2Ffd0656fElwsS8Hk4HNZlw7\n",
       "5Pu+OIr2JX95zx1CfX5POuug1pE0pkpwnIFwzz5lMsoqBu1FkwrtR9GufxBYFfYNPDdL0RlSVpjG\n",
       "6NlYVD3rrXp8SXCxLweDNqymSWsj7AwiC6fdPqc/3LN3ho6LfcpkNDdHLpl9oCV7v/B4thT7SmX2\n",
       "Q5pbJVfPPo/7Douqx5cEF/ty0O+0xFnQIujj9uWl3jeVs3GGhGf2ztBxsU+ZjDzDPG2clh4379mN\n",
       "Fhsn9BaqBEPsZ59LA23VPe2qx5cEF/uCIzEB2JH+Z6pMm1arptHtErMXBWvXYVeq5Hhm7wwdF/sB\n",
       "kJDEmO6vicf1OGaHAW876EyVafNiI6zEeLh6Z6LZFrfaXwWG5Pnm1hun6p521eNLQj8Ljs+XNCpp\n",
       "edO2CZKWSlopaYmkcU3br5W0SdI3sqx4TpwNPEk0F0yH1w+u6r6fp6SBRsLm2TgLkY1zoMQrgbfB\n",
       "Uw+0fPFUrpF2CHhm7wydfjL7S4DjW7bNA5aa2XSiibXmhe2bgf8J/G1qNSwWhwFnmDGm82vODt32\n",
       "Az8Epg1wzzz9eoD7iL6k5gN/Cyde2rK/Uo20PjdOual6fEnoOYLWzG6QNNKy+STg2PB+IXAdMM/M\n",
       "ngT+S9JBKdaxSEwDfpvwGoOK4ywY+sjZFzFjI3BUl0MqZeMMCc/snaET17OfZGaj4f0oLeuUQnXm\n",
       "N2+hp9j34RkOanvk2e1yK9rEV5nMXuJvpGuekvhjy2tUYucUb5Vbb5yqe9pVjy8JiefGMTOTNLC4\n",
       "S1rASzMwbgSWNX6CNT6wYpWn7wz3jAVGE15vDfz7W6R3z+51PNhNwF4wdn9p89Ri/XtsEc9b+4mn\n",
       "6GWwV8FvvgGnXxOV778h+vvTlfCtt8Oi76RxP7hqMlw+Ay4pVPxeLlY5MJtoVbHkmFnPV7jZ8qby\n",
       "CmDv8H4ysKLl+NOAb3S5nvVz3yK9wI4Auz2F68wBu67PY18Fdlvesfeo42yw6/OuR0qx3Ah2TJvt\n",
       "14PNTvE+94DNzDtef5XrlVQ349o4i4OgN4R9Ucv+ygyyaSINvx4G87gLZeF0oDI2DlFSs6rN9rRj\n",
       "dM/eGTr9dL28DLgRmCFptaQzgPOA4yStBOaEcuP4VcA/AKdLul/SzExqPnz6Evs+PMOuwiExIvE5\n",
       "ic8BZ5BvT5ytaBNfJUbRSuwI7AFjp7fZnXYjtM+NkxFVjy8J/fTGObXDrrkdjh9JUqECM41oke2k\n",
       "PA5sI7GrWdtGuncCxxH1wPkv4Hsp3DMzzNikSObLvhbtfsBq2PxCm32pZfZNi417Zu8MFV+8pH+m\n",
       "EfWR74r16OdrhkkvZortxH4acJkZF8apZNZ0iK8RT5nFfgRY1SW+I1K6T2qLjceh1/NZdqoeXxJ8\n",
       "uoT+Scuzh+6ZYpr3GRb3AHdJPNfy+kXeFRuAETqvz5umjeNZvZMLLvZ9IDEG2Bu4v/exfXmG3cSj\n",
       "0GLfIb6TgTFEE7Y1XlOAQ4ZXs8SMAKs6xJdmA22uYl91T7vq8SXBxb4/RoAHzHg2peu1HVgVJkmb\n",
       "AvwhpfsMBTNeMOO55hfwEDBWYmze9euTETyzdyqMi31/9J1t9+kZdsoU9wceTPFLJXX69UTNMLaa\n",
       "C7/QjNDZs98ESEplKudcxb7qnnbV40uCi31/pG2tdMoUC23hxKBMM2IeQIfMvumLK41Ycpsqwak3\n",
       "Lvb90bcI9+kZdhKOwov9gJ5oKTL7YDWNB9Z0iS8tKye3ueyh+p521eNLgot9f0wjmuo3LTyzLxb7\n",
       "AavNaNfHvkGamb179s7QcbHvj7Q9+04iWHixH9ATLctUCiMEC6dLfJXI7KvuaVc9viS42PdAYhsi\n",
       "P/d3KV52E2EUbcv2wov9gJRlrvsROvfEaZDWr5TxwIYUruM4A+Fi35t9gI1m/LGfg/vxDEOD3xZC\n",
       "GIbRH0i6XyqpM6AnWhYbZ4Qg9l3iS+tXSq5iX3VPu+rxJaHS0yVIbAt8C9gtwWUmkE223RCPlaE8\n",
       "GXi8w3w5ZaUUDbREYn9lj2PS+pUyHrgzhes4zkBUWuyBfYmWUPxYwuv0PfPkAJ5ha9b7Mkpg4Qzo\n",
       "iZYus+8SXyUy+6p72lWPLwlVF/uXAXeb8e95V6QNrZli1fx6iERtrMRYM57KuzJdGME9e6fiVN2z\n",
       "H7qADuAZtmaKpRD7QTzRMoyibepjvzYqd4xvUzg+6Sha9+wzpOrxJcHFPj/qkNlD8a2cfvrYpzmK\n",
       "1jN7JxeqbuP0NQd9mgzgGZYys4/hiRYusw+rUn2DaHbOvWiaeK5HfI0v6HsS3N49+wypenxJqIPY\n",
       "F1VAWzPeItc1CUXM7PcHTgTODuXb+zwvUWYvsT3RF0yVelw5JaGyNk7ot15kz34NMEXiAIlDgR2I\n",
       "pgUuNDE80SKOoh1PZN18J7xua+zoEV/SL67xwIZgCeVC1T3tqseXhK5iL2m+pFFJy5u2TZC0VNJK\n",
       "SUskjWvad46keyWtkPTmLCveBxOB58wK649uAu4ArgEWAz/JUwQypIijaCcQz0pJGov79U5u9Mrs\n",
       "LwGOb9k2D1hqZtOBq0MZSQcD7wIODudcKCnPXw652CKDzPduxlFmHBBe78y4aqkQwxMtoo0zHni0\n",
       "3Y4e8SX9lZK72Ffd0656fEnoKsZmdgNbP5wnAQvD+4XAKeH9ycBlZvasma0imiXyyPSqOjBV9cDL\n",
       "RuEaaIkvumuAqRK7t3kpw/s6TmLiNNBOMrPR8H4UmBTeTwH+u+m4B4jmlWmLxLkx7t2gn4FSuYi9\n",
       "pNlVzi5ixFfUzL6t6PaI7z5gJluvRbwj8FHgorj3HRb+fNaXRL1xzMwkdfOZu+w7+hTYZ2P0frfN\n",
       "cOQ6OHNVVL5oJPrbtrw7/Oxr0vGjjQ+10SizZfl7r4NTf9B5v5eHVN4A1+wsvffNZmuXFKA+wIJD\n",
       "YdMjkT4PfP7ErfdfeBGMmQ1/cVG388HGAxvyjt/L5SgHZhON8E6MzLq3CUoaAa4ws0NDeQUw28zW\n",
       "SZoMXGtmMyXNCxU+Lxz3U+DzZvarNtc0M+vnZ2+b+rAz8DCwU7cGTYlfAJ8x4/o493HSQ+L3wJvM\n",
       "ijGjp8QlwC/MuDil650OzDHjz3sc91lgRzM+k8Z9nXqRRDchXtfLxcBp4f1pwKKm7e+WtIOkA4CD\n",
       "gF/HrVgnwlTDTwPjehzqnn1xKJqVk7ad0m8vndxtHKe+9Op6eRlwIzBD0mpJZwDnAcdJWgnMCWXM\n",
       "7C7gB8BdwE+AD1uvnw3x6dorImT/44j+Ew6VqvfzjRlf0Rppu3r2Ma7Xby+d3MXen8/60tWzN7NT\n",
       "O+ya2+H4LwFfSlqpPmhkUp3mBT8Q+F2v+U6coVGHzL4UYu/Ul7KOoO2VSeVm4VS9J0DM+Eoj9jHj\n",
       "e5QwlXPc+w4Lfz7rS1nFvpdHWoqFQGpE0aZMSFV0Q0eBdfS2qnIXe6e+lHUitDVEi4B3Yho5Lf1W\n",
       "9X6+MePr+uUcFnW/mEgMu3GuGcsGvHfrvbpORpbg82vE2K3HUceRu8PCn8/6UlaxXwsc3WX/NKLe\n",
       "QU4x6NVAOxH4U+D0Lsd8gKjPcSKxJxLcjRnMQ9TPrxfP7J3cKKvY97Jx3LPPiIw8+32A+81e7Ma7\n",
       "FRIzSW/B746Cm+Dz6xpj+EUxBngi5vVTwZ/P+lJWz75jFiUxhkg8fj/UGjndeHEt2g779wEe7HGN\n",
       "oi/43SsByeoXheP0RanFvsPkU9OAP5jx7JDrBFS/n2+c+PpYi7YfsU9rquSuYp/g8+v1ZVQIC8ef\n",
       "z/pSSrEPo2g3034U7XRg5XBr5PRBN5tjmJl93Lnse9FPZp+72Dv1pZRiH+j0n386ydYITUTVPcME\n",
       "8aWR2adl43TsEZOVZ09BxN6fz/pSZrHvlEnNwDP7IpI0s98A7CixU8J6ZCW6pbBxnPpSZrHvltnn\n",
       "JvZV9wwz8rR7in0fvn+/ZOXZ9xpFWwix9+ezvpRZ7Dtliu7ZF5NunvYUemf2va7RL5mIbh+jaAsh\n",
       "9k59KbvYb/EfS2IcsBNRBpgLVfcM0/a0Qya8C9EaBb1Io5E2q3720P3LKKuG4YHw57O+lFns2/3H\n",
       "PwhY6X2ZC0knC2YKsLbPzyyNRtosM+xu9fPM3smVMot9uywq98bZqnuGCeLrJIT9NM42KLJnD91/\n",
       "eeQ+Lw7481lnyi72rf+x3K8vLp1G0Q4i9mXI7N2zdwpJmcV+LTC5ZRRt7mJfdc8wbnxdetMUSuwT\n",
       "fn69Mvvcxd6fz/pSWrE340m2Xos2d7F3utJOrIdm4/Sa3jgFPLN3CktssZd0lqTlku6QdFbYdrik\n",
       "X0q6XdL+Bc5JAAAIR0lEQVRiSbumV9W2vJhJhQw/d7GvumeYgqedZ2bfczKyhPEVvoHWn8/6Ekvs\n",
       "Jb0c+CDwGuBw4ERJ04B/A842s8OA/wd8Mq2KdqA5k5oCPGHGYxnf04lP0sw+6SjarAW3rY1TlOmN\n",
       "nXoTN7OfCfzKzDab2fPA9cA7gIPM7IZwzH+GbVnSLB65Z/VQfc8wA0+7b7FPYRRtT7FPGF+nUbSF\n",
       "md7Yn8/6Elfs7wBeL2mCpJ2AtwH7AndIOjkc82fA1BTq2I1m8SiE2Dtd2cLTDssRTg7b+yXJwKpM\n",
       "M/umUbSvk5jZeAFHZHlfx+mHWGJvZiuA84ElwE+Ilop7HvgL4MOSbiIaFflMSvXsxBrgVImLgL+k\n",
       "AGJfdc8wZU97IpH19tSA18gss0/h81sCfBNY1PT6OtGv39zx57O+xF6W0MzmA/MBJH0JuN/M7gHe\n",
       "ErZNB07odL6kBcCqUNwILGv8BGt8YL3KYN8HnoSvTAeugU9+e5DzvTzcMlhYdObF8mPAgwNebw38\n",
       "0xukv14f4/7jgQ1ZxmvGmV3uT5b/vl6uVjkwGxghBWQWz0aUtJeZrZe0H/Az4LXAGDN7SNI2wALg\n",
       "GjNb0OZcM7N2q0w5FUZiAvBbM8aH8onAR8x46wDXOAcYZ8anYtz/s8BYMz496LmOkzdJdTNJP/vL\n",
       "Jd0JLAY+bGaPA6dKuge4G3igndA7taZ1FO0gPXEaJOl+WYgpCxwnD2KLvZm9wcwOMbNXmNm1Yds/\n",
       "m9mM8Kpl9lR1zzBJfG1608QR+0wbaP3zKzdVjy8JpR1B65SW5sw8bmafWQOt41QVF/uUqXo/3xTi\n",
       "WwscJXE4UXfZQmX2/vmVm6rHlwQXe2fYXAu8H/g20UIzdwx4/qPEH0Xrmb1TW2L3xkl00wr3xpE0\n",
       "u8rZRRHik7iPaOqBQcdxHA5MM+OBztfOP74s8fjKS1LdjN3P3nFyZC6wV4zzNncTesepMp7ZO47j\n",
       "lIA8+9k7juM4JcHFPmWq3s/X4ys3Hl99cbF3HMepAe7ZO47jlAD37B3HcZyeuNinTNU9Q4+v3Hh8\n",
       "9cXF3nEcpwa4Z+84jlMC3LN3HMdxeuJinzJV9ww9vnLj8dUXF3vHcZwa4J694zhOCXDP3nEcx+lJ\n",
       "bLGXdJak5ZLukHRW2HakpF9LulXSbyS9Jr2qloOqe4YeX7nx+OpLLLGX9HLgg8BriBaEOFHSNOAC\n",
       "4LNm9krgc6FcN16RdwUyxuMrNx5fTYm7eMlM4FdmthlA0vXA24kWg949HDOOwdcXrQLj8q5Axnh8\n",
       "5cbjqylxxf4O4IuSJgCbgROAXwPzgBslfZXoV8OfpFJLx3EcJxGxbBwzWwGcDywBfgLcCrwAXAx8\n",
       "1Mz2Az4OzE+pnmViJO8KZMxI3hXImJG8K5AxI3lXIGNG8q5AUUml66WkLwIPAOeb2W5hm4CNZrZ7\n",
       "m+OH39/TcRyn5OSy4LikvcxsvaT9iPz6o4APSTrWzK4H5gAr253rfewdx3GGS2yxBy6XtAfwLPBh\n",
       "M3tM0pnANyWNAZ4Czkyjko7jOE4ychlB6ziO4wyXoY6glXS8pBWS7pX0qWHeOwskTZV0raQ7w+Cy\n",
       "j4XtEyQtlbRS0hJJpe0OJmnbMEjuilCuUmzjJF0u6W5Jd0l6bcXiOyc8m8slfU/SmDLHJ2m+pFFJ\n",
       "y5u2dYwnxH9v0Jw351Pr/ukQ31fC83mbpB9J2r1p30DxDU3sJW0L/AtwPHAwcKqkWcO6f0Y8C3zc\n",
       "zA4harP4SIhpHrDUzKYDV4dyWTkLuAto/ASsUmz/BPzYzGYBhwErqEh8kkaADwFHmNmhwLbAuyl3\n",
       "fJcQ6UczbeORdDDwLiKtOR64UFLRp4dpF98S4BAzO5yoDfQciBffMIM/ErjPzFaZ2bPA94GTh3j/\n",
       "1DGzdWa2LLx/Argb2Ac4CVgYDlsInJJPDZMhaV/gbcC/AY1G9arEtjvwejObD2Bmz5nZY1QkPuBx\n",
       "omRkJ0nbATsRDXosbXxmdgOwoWVzp3hOBi4zs2fNbBVwH5EGFZZ28ZnZUjN7IRR/Bewb3g8c3zDF\n",
       "fh9gdVP5gbCtEoRM6pVEH8gkMxsNu0aBSTlVKylfAz5JNIaiQVViOwB4SNIlkm6R9K+SdqYi8ZnZ\n",
       "o8A/APcTifxGM1tKReJrolM8U4g0pkEV9OYDwI/D+4HjG6bYV7YlWNIuwP8FzjKzTc37LGoBL13s\n",
       "kk4E1pvZrbyU1W9BWWMLbAccAVxoZkcAf6TF0ihzfGGuqr8mGmQ0BdhF0vuajylzfO3oI57Sxirp\n",
       "M8AzZva9Lod1jW+YYv8gMLWpPJUtv5lKiaTtiYT+O2a2KGwelbR32D8ZWJ9X/RLwOuAkSb8HLgPm\n",
       "SPoO1YgNomfvATP7TShfTiT+6yoS36uBG83sETN7DvgR0fQlVYmvQafnsVVv9qWkc3VJOp3ITn1v\n",
       "0+aB4xum2N8EHCRpRNIORI0Li4d4/9QJo4QvBu4ys6837VoMnBbenwYsaj236JjZp81sqpkdQNSw\n",
       "d42ZvZ8KxAZRewuwWtL0sGkucCdwBRWIj6ix+ShJY8NzOpeoob0q8TXo9DwuBt4taQdJBwAHEc3f\n",
       "VSokHU9kpZ7cmHgyMHh8Zja0F/BW4B6ixoRzhnnvjOI5hsjPXkY0P9CtRC3jE4D/JGo9XwKMy7uu\n",
       "CeM8Flgc3lcmNqLpuX8D3EaU+e5esfjOJvoCW07UeLl9meMj+oW5BniGqP3vjG7xAJ8OWrMCeEve\n",
       "9Y8R3weAe4E/NOnLhXHj80FVjuM4NaDo/U4dx3GcFHCxdxzHqQEu9o7jODXAxd5xHKcGuNg7juPU\n",
       "ABd7x3GcGuBi7ziOUwNc7B3HcWrA/wdlTVazYMxryQAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24be99a990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bankroll = 100.0\n",
    "trace = []\n",
    "for i in test_report.index:\n",
    "    stake = 1.0\n",
    "    # bet on home win\n",
    "    if test_report.loc[i, 'Predicted Outcome'] == 'A':\n",
    "        bankroll -= stake\n",
    "        # win the bet\n",
    "        if test_report.loc[i, 'True Outcome'] == test_report.loc[i, 'Predicted Outcome']:\n",
    "            bankroll += stake*test_report.loc[i, test_report.loc[i, 'True Outcome']]\n",
    "        # lost the bet\n",
    "        else:\n",
    "            pass\n",
    "    trace.append(round(bankroll, 2))\n",
    "\n",
    "plt.plot(range(len(test_report.index)), trace)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vanderplas learning curve\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "def plot_learning_curve(model, err_func=explained_variance_score, N=300, n_runs=10, n_sizes=50, ylim=None):\n",
    "    sizes = np.linspace(5, N, n_sizes).astype(int)\n",
    "    train_err = np.zeros((n_runs, n_sizes))\n",
    "    validation_err = np.zeros((n_runs, n_sizes))\n",
    "    for i in range(n_runs):\n",
    "        for j, size in enumerate(sizes):\n",
    "            xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "                X, y, train_size=size, random_state=i)\n",
    "            # Train on only the first `size` points\n",
    "            model.fit(xtrain, ytrain)\n",
    "            validation_err[i, j] = err_func(ytest, model.predict(xtest))\n",
    "            train_err[i, j] = err_func(ytrain, model.predict(xtrain))\n",
    "\n",
    "    plt.plot(sizes, validation_err.mean(axis=0), lw=2, label='validation')\n",
    "    plt.plot(sizes, train_err.mean(axis=0), lw=2, label='training')\n",
    "\n",
    "    plt.xlabel('traning set size')\n",
    "    plt.ylabel(err_func.__name__.replace('_', ' '))\n",
    "    \n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.legend(loc=0)\n",
    "    \n",
    "    plt.xlim(0, N-1)\n",
    "    \n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "\n",
    "\n",
    "X = load_boston().data\n",
    "y = load_boston().target\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, model in enumerate([Lasso(0.01), Ridge(0.06)]):\n",
    "    plt.subplot(221 + i)\n",
    "    plot_learning_curve(model, ylim=(0, 1))\n",
    "    plt.title(model.__class__.__name__)\n",
    "    \n",
    "    plt.subplot(223 + i)\n",
    "    plot_learning_curve(model, err_func=mean_squared_error, ylim=(0, 8000))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
